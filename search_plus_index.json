{"./":{"url":"./","title":"Introduction","keywords":"","body":"请访问: https://github.com/doctording/kafka-1.1.0-src 欢迎:star，fork，pr 或 email 源码配置参考：kafka-1.1.0 源码环境搭建 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-12-01 19:26:40 "},"content/basic.html":{"url":"content/basic.html","title":"消息队列基础","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 kafka基础 消息队列(Message Queue，简称MQ) 为什么需要消息队列 MQ的应用场景 MQ消息队列的两种消息模式 如何保证消息队列的高可用？ 如何保证消息不丢失？ 如何保证消息不被重复消费？如何保证消息消费的幂等性？ 重复消费的原因 解决方案 如何保证消息被消费的顺序性？ 常见的消息队列中间件 push 和 pull kafka基础 消息队列(Message Queue，简称MQ) 为什么需要消息队列 解藕 冗余 扩展性 灵活性 & 峰值处理能力 可恢复性 顺序保证 缓冲 异步通信 MQ的应用场景 消息队列的主要应用场景：解藕,异步,削峰，实现高性能、高可用、可伸缩和最终一致性架构，是大型分布式系统不可缺少的中间件； 应用耦合：多应用间通过消息队列对关心的消息进行处理，避免调用接口失败导致整个过程失败； 异步处理：多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间； 限流削峰：广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况； 消息驱动的系统：系统分为消息队列、消息生产者、消息消费者，生产者负责产生消息，消费者(可能有多个)负责对消息进行处理； MQ消息队列的两种消息模式 在JMS标准中，有两种消息模型P2P（Point to Point）,Publish/Subscribe(Pub/Sub)。 点对点模式 每个消息只有一个接收者（Consumer）(即一旦被消费，消息就不再在消息队列中)； 发送者和接收者间没有依赖性，发送者发送消息之后，不管有没有接收者在运行，都不会影响到发送者下次发送消息； 接收者在成功接收消息之后需向队列应答成功，以便消息队列删除当前接收的消息； 发布/订阅模式 每个消息可以有多个订阅者； 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。 为了消费消息，订阅者需要提前订阅该角色主题，并保持在线运行 如何保证消息队列的高可用？ 镜像集群模式 非分布式，如果某个 queue 负载很重，加机器，新增的机器也包含了这个 queue 的所有数据，并没有办法线性扩展 queue 分布式，备份 分布式消息队列，就是说一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据 例如 生产者写 leader，然后 leader 将数据落地写本地磁盘，接着其它 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者 消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到 如何保证消息不丢失？ 消息丢失的环节； 发送过程中丢失 MQ还未持久化消息，然后宕机了 消费者消费到消息但是未处理(此时MQ把消息已经删除了)，然后宕机了 如何保证不丢？ 生产者，MQ之间确认 MQ持久化 MQ，消费者之间确认 如何保证消息不被重复消费？如何保证消息消费的幂等性？ 重复消费的原因 消息重复的根本原因是网络不可达，且不可避免 生产者发送时未收到MQ的响应(可能网络闪断，不过最终MQ处理完成了)然后重发，最终也是成功处理，这会导致重复消息进入MQ，后续消费重复 消费者消费到消息，完成业务处理，当消费者给MQ服务端反馈应答的时候网络闪断。MQ还保留着消息，保证消息至少被消费一次，在网络恢复后再次把消息尝试投递给消费者去处理，这样消费者就收到两条一样的消息了 解决方案 消息发送者发送消息时携带一个全局唯一的消息id 消费者获取消息后，先根据id在 redis/db 中查询是否之前 该记录被消费过了 如果没有被消费过，则消费并写入 redis/db; 否则直接忽略 如何保证消息被消费的顺序性？ 消息有序是指：按照消息发送的顺序来消费 生产者保证消息的顺序到达MQ 消费者保证顺序消费MQ中的消息 1:1:1，局部顺序消费 常见的消息队列中间件 特性 ActiveMQ RabbitMQ RocketMQ kafka 开发语言 java erlang java scala 单机吞吐量 万级 万级 10万级 10万级 时效性 ms级 us级 ms级 ms级以内 可用性 高(主从架构) 高(主从架构) 非常高(分布式架构) 非常高(分布式架构) 功能特性 成熟的产品，在很多公司得到应用；有较多的文档；各种协议支持较好 基于erlang开发，所以并发能力很强，性能极其好，延时很低;管理界面较丰富 MQ功能比较完备，扩展性佳 只支持主要的MQ功能，像一些消息查询，消息回溯等功能没有提供，毕竟是为大数据准备的，在大数据领域应用广。 push 和 pull x push模型 pull模型 描述 服务端主动发送数据给客户端 客户端主动从服务端拉取数据，通常客户端会定时拉取 实时性 较好，收到数据后可立即发送给客户端 一般，取决于pull的间隔时间 服务端状态 需要保存push状态，哪些客户端已经发送成功，哪些发送失败 服务端无状态 客户端状态 无需额外保存状态 需保存当前拉取的信息的状态，以便在故障或者重启的时候恢复 状态保存 集中式，集中在服务端 分布式，分散在各个客户端 负载均衡 服务端统一处理和控制 客户端之间做分配，需要协调机制，如使用zookeeper 其它 服务端需要做流量控制，无法最大化客户端的处理能力；其次，在客户端故障情况下，无效的push对服务端有一定负载。 客户端的请求可能很多无效或者没有数据可供传输，浪费带宽和服务器处理能力 缺点方案 服务器端的状态存储是个难点，可以将这些状态转移到DB或者key-value存储，来减轻server压力。 针对实时性的问题，可以将push加入进来，push小数据的通知信息，让客户端再来主动pull。针对无效请求的问题，可以设置逐渐延长间隔时间的策略，以及合理设计协议尽量缩小请求数据包来节省带宽。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-10-24 16:01:01 "},"content/kafka_basic.html":{"url":"content/kafka_basic.html","title":"kafka基础","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 kafka基础 kafka架构 kafka基础概念 Replica（副本） AR && ISR 伸缩性(broker可扩展性，分布式) Kafka的持久化 kafka基础 kafka架构 Kafka中消息是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的 Producer将每一条消息顺序IO追加到partition对应到log文件末尾 每条消息都有一个offset Partition是用来存储数据的，但并不是最小的数据存储单元。Partition下还可以细分成Segment，每个Partition是由一个或多个Segment组成。每个Segment分别对应两个文件：一个是以.index结尾的索引文件，另一个是以.log结尾的数据文件，且两个文件的文件名完全相同。所有的Segment均存在于所属Partition的目录下。 消息按规则路由到不同的partition中，每个partition内部消息是有序的，但是不同partition之间不是有序的 Producer生产消息push到Kafka集群；Consumer通过pull的方式从Kafka集群拉取消息 kafka基础概念 Replica（副本） Kafka 定义了两类副本：领导者副本（Leader Replica）和追随者副本（Follower Replica） 前者对外提供服务，这里的对外指的是与客户端程序进行交互； 后者只是被动地追随领导者副本而已，不能与外界进行交互。当然，你可能知道在很多其他系统中追随者副本是可以对外提供服务的，比如 MySQL 的从库是可以处理读操作的，但是在 Kafka 中追随者副本不会对外提供服务。 AR && ISR 分区中的所有副本统称为AR(Assigned Replicas)。 所有与leader副本保持一定程度同步的副本（包括leader副本在内）组成ISR(In Sync Replicas)。 ISR 集合是 AR 集合的一个子集。消息会先发送到leader副本，然后follower副本才能从leader中拉取消息进行同步。同步期间，follower副本相对于leader副本而言会有一定程度的滞后。前面所说的 ”一定程度同步“ 是指可忍受的滞后范围，这个范围可以通过参数进行配置 leader副本同步滞后过多的副本（不包括leader副本）将组成OSR （Out-of-Sync Replied） AR = ISR + OSR。正常情况下，所有的follower副本都应该与leader 副本保持 一定程度的同步，即AR=ISR，OSR集合为空 0.9.0.0 版本之前判断副本之间是否同步，主要是靠参数replica.lag.max.messages决定的，即允许 follower 副本落后 leader 副本的消息数量，超过这个数量后，follower 会被踢出 ISR。replica.lag.max.messages也很难在生产上给出一个合理值，如果给的小，会导致 follower 频繁被踢出 ISR，如果给的大，broker 发生宕机导致 leader 变更时，可能会发生日志截断，导致消息严重丢失的问题。 在 0.9.0.0 版本之后，Kafka 给出了一个更好的解决方案，去除了replica.lag.max.messages，用replica.lag.time.max.ms参数来代替，该参数的意思指的是允许 follower 副本不同步消息的最大时间值，即只要在replica.lag.time.max.ms时间内 follower 有同步消息，即认为该 follower 处于 ISR 中，这就很好地避免了在某个瞬间生产者一下子发送大量消息到 leader 副本导致该分区 ISR 频繁收缩与扩张的问题了。 伸缩性(broker可扩展性，分布式) 虽然有了副本机制可以保证数据的持久化或消息不丢失，但没有解决伸缩性的问题。伸缩性即所谓的 Scalability，，是分布式系统中非常重要且必须要谨慎对待的问题。什么是伸缩性呢？我们拿副本来说，虽然现在有了领导者副本和追随者副本，但倘若领导者副本积累了太多的数据以至于单台 Broker 机器都无法容纳了，此时应该怎么办呢？一个很自然的想法就是，能否把数据分割成多份保存在不同的 Broker 上？如果你就是这么想的，那么恭喜你，Kafka 就是这么设计的。这种机制就是所谓的分区（Partitioning） Kafka的持久化 Kafka直接将数据写入到日志文件中，以追加的形式写入，避免随机访问磁盘，而是顺序读写方式 一个Topic可以认为是一类消息，每个topic将被分成多partition(区)，每个partition在存储层面是append log文件。任何发布到此partition的消息都会被直接追加到log文件的尾部，每条消息在文件中的位置称为offset（偏移量），partition是以文件的形式存储在文件系统中 Logs文件根据broker中的配置要求，保留一定时间后删除来释放磁盘空间 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-12-10 10:45:05 "},"content/producer.html":{"url":"content/producer.html","title":"KafkaProducer","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Producer topic的创建和数据生成和落磁盘文件 消息路由到不同的partition 查看磁盘上的kafka-logs文件目录下对应的topic文件 topic分partition的原因与实现 分区的原因 生产者发送进行分区的原则？ Producer如何将消息可靠的发送给Kafka集群 ack应答机制（3种策略） retries batch.size linger.ms requests.timeout.ms max.in.flight.requests.per.connection ISR 机制 和 数据一致性 LEO & HW 保证副本的数据一致性 follower故障 leader故障 0.11版本之后 幂等 & Exactly Once 语义 事务应用场景 事务处理 KafkaProducer源码 KafkaProducer 交互简图 源码流程图 元数据交互 元数据更新重难点 序列化 计算 record 要发送到的 partition？ accumulator.append() RecordAccumulator append方法的源码流程 sender线程处理流程 sender源码 sendProducerData 超时消息的处理 client.poll Producer topic的创建和数据生成和落磁盘文件 创建topic名称为：kafkatest 三台broker(0,1,2), 设置topic的partition数目是2，replication备份因子是2 对于partition 0，leader 是 3，follower 是 1，两个备份 对于partition 1，leader 是 1，follower 是 2，两个备份 一次发送了4条消息，内容分别是 空 a1 b1 c1 消息路由到不同的partition 空和b1存储到了partition 0中 a1和c1存储到了partition 1中 查看磁盘上的kafka-logs文件目录下对应的topic文件 对于partition 0，leader 是 3，follower 是 1 对于partition 1，leader 是 1，follower 是 2 登录到三台机器分别查看 broker 1 包含了kafkatest-0和kafkatest-1两个目录文件 broker 2 只包含kafkatest-1两个目录文件 broker 3 只包含kafkatest-0两个目录文件 topic分partition的原因与实现 分区的原因 方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了 可以提高并发，因为可以以Partition为单位读写了 生产者发送进行分区的原则？ 我们需要将producer发送的数据封装成一个ProducerRecord对象，然后发送 指明 partition 的情况下，直接将指明的值直接作为要发送的 partiton 值； 没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与topic的partition总数进行取余得到一个 partition 值； 既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法（轮询）。 Producer如何将消息可靠的发送给Kafka集群 ack应答机制（3种策略） acks指定了必须有多少个分区副本接收到了消息，生产者才会认为消息是发送成功的。 acks=0，生产者成功写入消息之前不会等待来自任何服务器的响应，这种配置，提高吞吐量，但是消息存在丢失风险。 acks=1，只要集群的leader（master）收到了消息，生产者将会受到发送成功的一个响应，如果消息无撞到达首领节点（比如首领节点崩溃，新的首领还没有被选举出来），生产者会收到一个错误响应，为了避免数据丢失，生产者会重发消息。不过，如果一个没有收到消息的节点成为新首领，消息还是会丢失。这个时候的吞吐量取决于使用的是同步发送还是异步发送。如果让发送客户端等待服务器的响应（通过调用Future 对象的get（）方法，显然会增加延迟（在网络上传输一个来回的延迟）。如果客户端使用回调，延迟问题就可以得到缓解，不过吞吐量还是会受发送中消息数量的限制（比如，生产者在收到服务器响应之前可以发送多少个消息）。 acks=-1，所有参与复制的节点全部收到消息的时候，生产者才会收到来自服务器的一个响应，这种模式最安全，但是吞吐量受限制，它可以保证不止一个服务器收到消息，就算某台服务器奔溃，那么整个集群还是会正产运转。 retries 生产者从服务器收到的错误消息有可能是临时的，当生产者收到服务器发来的错误消息，会启动重试机制，当重试了n（设置的值）次，还是收到错误消息，那么将会返回错误。生产者会在每次重试之间间隔100ms，不过可以通过retry.backoff.ms改变这个间隔。 batch.size 当多个消息发往同一个分区，生产者会将他们放进同一个批次，该参数指定了一个批次可以使用的内存大小，按照字节数进行计算(不是消息个数)；当批次被填满，批次里面所有得消息将会被发送；半满的批次，甚至只包含一个消息也可能会被发送，所以即使把批次设置的很大，也不会造成延迟，只是占用的内存打了一些而已。但是设置的太小，那么生产者将会频繁的发送小，增加一些额外的开销。 linger.ms 该参数指定了生产者在发送批次之前等待更多消息加入批次的时间。KafkaProducer会在批次填满或linger.ms达到上限时把批次发送出去。默认情况下，只要有可用的线程， 生产者就会把消息发送出去，就算批次里只有一个消息。把linger.ms设置成比0大的数，让生产者在发送批次之前等待一会儿，使更多的消息加入到这个批次。虽然这样会增加延迟，但也会提升吞吐量（因为一次性发送更多的消息，每个消息的开销就变小了） requests.timeout.ms 生产者发送数据时等待服务器返回响应的时间 max.in.flight.requests.per.connection 指定了生产者收到服务器响应之前可以发送多少个消息。它的值越高，将会消耗更多的内存，不过也会提升吞吐量。设置为1，可以保证消息是按照发送的顺序写入服务器。即使发生了重试。 ISR 机制 和 数据一致性 Leader维护了一个动态的in-sync replica set (ISR)，意为和leader保持同步的follower集合。当ISR中的follower完成数据的同步之后，leader就会给follower发送ack。如果follower长时间未向leader同步数据，则该follower将被踢出ISR，该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障之后，就会从ISR中选举新的leader Kafka 的复制机制既不是完全的同步复制，也不是单纯的异步复制。完全同步复制要求所有能工作的 Follower 都复制完，这条消息才会被认为 commit，这种复制方式极大的影响了吞吐率（高吞吐率是 Kafka 非常重要的一个特性）。而异步复制方式下，Follower 异步的从 Leader 复制数据，数据只要被 Leader 写入 log 就被认为已经 commit，这种情况下如果 Follower 都复制完都落后于 Leader，而如果 Leader 突然宕机，则会丢失数据。 #### LEO & HW 保证副本的数据一致性 * LEO：指的是每个副本最大的offset * HW：指的是消费者能见到的最大的offset，ISR队列中最小的LEO ![](../imgs/hw_leo.png) ![](../imgs/hw_leo2.jpeg) #### follower故障 follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即follower追上leader之后，就可以重新加入ISR了。 #### leader故障 leader发生故障之后，会从ISR中选出一个新的leader；之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据。 注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复 ### 0.11版本之后 幂等 & Exactly Once 语义 对于某些比较重要的消息，我们需要保证exactly once语义，即保证每条消息被发送且仅被发送一次。 在0.11版本之后，Kafka Producer引入了幂等性机制（`idempotent` n. 幂等性），配合acks = -1时的at least once语义，实现了producer到broker的exactly once语义。 `idempotent + at least once = exactly once` 使用时，只需将`enable.idempotence`属性设置为true（kafka会自动将`acks`属性设为-1） #### 事务应用场景 kafka的应用场景经常是应用先消费一个topic，然后做处理再发到另一个topic，这个`consume-transform-produce`过程需要放到一个事务里面，比如在消息处理或者发送的过程中如果失败了，消费位点也不能提交。 #### 事务处理 producer提供了`initTransactions`, `beginTransaction`, `sendOffsets`, `commitTransaction`, `abortTransaction` 五个事务方法。 ```java import org.apache.kafka.clients.consumer.ConsumerRecord; import org.apache.kafka.clients.consumer.ConsumerRecords; import org.apache.kafka.clients.consumer.KafkaConsumer; import org.apache.kafka.clients.consumer.OffsetAndMetadata; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; import org.apache.kafka.common.TopicPartition; import java.util.Arrays; import java.util.HashMap; import java.util.Map; import java.util.Properties; import java.util.concurrent.Future; public class consumeTransformProduce { private static Properties getProducerProps(){ Properties props = new Properties(); props.put(\"bootstrap.servers\", \"47.52.199.51:9092\"); props.put(\"retries\", 3); // 重试次数 props.put(\"batch.size\", 100); // 批量发送大小 props.put(\"buffer.memory\", 33554432); // 缓存大小，根据本机内存大小配置 props.put(\"linger.ms\", 1000); // 发送频率，满足任务一个条件发送 props.put(\"client.id\", \"producer-syn-2\"); // 发送端id,便于统计 props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); props.put(\"transactional.id\",\"producer-2\"); // 设置事务Id,每台机器唯一 props.put(\"enable.idempotence\",true); // 设置幂等性 return props; } private static Properties getConsumerProps(){ Properties props = new Properties(); props.put(\"bootstrap.servers\", \"47.52.199.51:9092\"); props.put(\"group.id\", \"test_3\"); props.put(\"session.timeout.ms\", 30000); // 如果其超时，将会可能触发rebalance并认为已经死去，重新选举Leader props.put(\"enable.auto.commit\", \"false\"); // 开启自动提交 props.put(\"auto.commit.interval.ms\", \"1000\"); // 自动提交时间 props.put(\"auto.offset.reset\",\"earliest\"); // 从最早的offset开始拉取，latest:从最近的offset开始消费 props.put(\"client.id\", \"producer-syn-1\"); // 发送端id,便于统计 props.put(\"max.poll.records\",\"100\"); // 每次批量拉取条数 props.put(\"max.poll.interval.ms\",\"1000\"); props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); props.put(\"isolation.level\",\"read_committed\"); // 设置隔离级别 return props; } public static void main(String[] args) { // 创建生产者 KafkaProducer producer = new KafkaProducer<>(getProducerProps()); // 创建消费者 KafkaConsumer consumer = new KafkaConsumer<>(getConsumerProps()); // 初始化事务 producer.initTransactions(); // 订阅主题 consumer.subscribe(Arrays.asList(\"consumer-tran\")); for(;;){ // 开启事务 producer.beginTransaction(); // 接受消息 ConsumerRecords records = consumer.poll(500); // 处理逻辑 try { Map commits = new HashMap<>(); for(ConsumerRecord record : records){ // 处理消息 System.out.printf(\"offset = %d, key = %s, value = %s\\n\", record.offset(), record.key(), record.value()); // 记录提交的偏移量 commits.put(new TopicPartition(record.topic(), record.partition()),new OffsetAndMetadata(record.offset())); // 产生新消息 Future metadataFuture = producer.send(new ProducerRecord<>(\"consumer-send\",record.value()+\"send\")); } // 提交偏移量 producer.sendOffsetsToTransaction(commits,\"group0323\"); // 事务提交 producer.commitTransaction(); }catch (Exception e){ e.printStackTrace(); producer.abortTransaction(); } } } } ``` ## KafkaProducer源码 ### KafkaProducer 交互简图 ![](../imgs/kafka_producer_frame.png) 所以重点要关心：1. 元数据，2. 数据如何发送 同步发送如下图： ![](../imgs/kafka_produce_sync.png) ### 源码流程图 ![](../imgs/producer3.png) ```java KafkaProducer send doSend(ProducerRecord record, Callback callback) waitOnMetadata() （集群和topic元信息） serialize（serializedKey, serializedValue构造） partition() (获取一个分区号) new TopicPartition ensureValidRecordSize() 校验record的size timestamp Callback accumulator.append() RecordAccumulator private final ConcurrentMap> batches; tryAppend(timestamp, key, value, headers, callback, dq); this.sender.wakeup(); sender thread run() long pollTimeout = sendProducerData(now); this.accumulator.drain() this.accumulator.expiredBatches sendProduceRequests(batches, now); ClientRequest client.send(clientRequest, now); client.poll(pollTimeout, now); NetworkClient poll() this.selector.poll(Utils.min(timeout, metadataTimeout, requestTimeoutMs)); ``` ![](../imgs/producer1.png) ![](../imgs/producer2.png) #### 元数据交互 sender从kafka集群获取信息，然后更新Metadata；KafkaProducer先读取Metadata，然后才能确定开始消息写入流程 可以看到Metadata是有多个客户端线程(即KafkaProducer线程)读，一个sender线程更新，因此它必须是线程安全的，查看源码可以看到其所有方法都是加上`synchronized`关键字的 ```java /** * A class encapsulating some of the logic around metadata. * * This class is shared by the client thread (for partitioning) and the background sender thread. * * Metadata is maintained for only a subset of topics, which can be added to over time. When we request metadata for a * topic we don't have any metadata for it will trigger a metadata update. * * If topic expiry is enabled for the metadata, any topic that has not been used within the expiry interval * is removed from the metadata refresh set after an update. Consumers disable topic expiry since they explicitly * manage topics while producers rely on topic expiry to limit the refresh set. */ public final class Metadata { ... public synchronized Cluster fetch() public synchronized void add(String topic) public synchronized long timeToNextUpdate(long nowMs) public synchronized int requestUpdate() public synchronized boolean updateRequested() public synchronized void awaitUpdate(final int lastVersion, final long maxWaitMs) ... } ``` * `org.apache.kafka.clients.producer.KafkaProducer#waitOnMetadata` ```java /** * Wait for cluster metadata including partitions for the given topic to be available. * @param topic The topic we want metadata for * @param partition A specific partition expected to exist in metadata, or null if there's no preference * @param maxWaitMs The maximum time in ms for waiting on the metadata * @return The cluster containing topic metadata and the amount of time we waited in ms */ private ClusterAndWaitTime waitOnMetadata(String topic, Integer partition, long maxWaitMs) throws InterruptedException { /** * metadata维护了topic和过期时间的Map结构(即 topic expiry)：Map topics; * add 会判断是否命中了Map且时间过期判断并更新，否则要进行Metadata的更新（由sender线程负责更新） * 注：add方法在新增topic时候才会`requestUpdateForNewTopics`，更新标记（Metadata的成员属性needUpdate） */ // add topic to metadata topic list if it is not there already and reset expiry metadata.add(topic); Cluster cluster = metadata.fetch(); Integer partitionsCount = cluster.partitionCountForTopic(topic); // Return cached metadata if we have it, and if the record's partition is either undefined // or within the known partition range // 指定分区空，或者是小于分区总数的和合理值，就返回 if (partitionsCount != null && (partition == null || partition = maxWaitMs) throw new TimeoutException(\"Failed to update metadata after \" + maxWaitMs + \" ms.\"); if (cluster.unauthorizedTopics().contains(topic)) throw new TopicAuthorizationException(topic); remainingWaitMs = maxWaitMs - elapsed; partitionsCount = cluster.partitionCountForTopic(topic); } while (partitionsCount == null); if (partition != null && partition >= partitionsCount) { throw new KafkaException( String.format(\"Invalid partition given with record: %d is not in the range [0...%d).\", partition, partitionsCount)); } return new ClusterAndWaitTime(cluster, elapsed); } ``` 元数据部分总结 1. KafkaProducer主线程和sender线程通过wait/notify同步。主线程负责发出更新信号和读取元数据，sender线程负责更新集群元数据 2. 为了避免频繁更新元数据给服务端造成压力，Metadata两次更新时间间隔不能小于refreshBackOffMs设计 3. Metadata使用version来表示元信息的版本，更新后版本就加1，通过比较新旧版本来判断Metadata是否更新完成 4. Metadata不是存放所有topic信息，而是维护使用到的topic的信息 #### 元数据更新重难点 刷新metadata并不仅在第一次初始化时做。为了能适应kafka broker运行中因为各种原因挂掉、partition改变等变化，eventHandler会定期的再去刷新一次该metadata，刷新的间隔用参数topic.metadata.refresh.interval.ms定义，默认值是10分钟 * 调用send, 才会新建SyncProducer，只有调用send才会去定期刷新metadata在每次取metadata时，kafka会新建一个SyncProducer去取metadata，逻辑处理完后再close。 * 根据当前SyncProducer(一个Broker的连接)取得的最新的完整的metadata，刷新ProducerPool中到broker的连接.每10分钟的刷新会直接重新把到每个broker的socket连接重建，意味着在这之后的第一个请求会有几百毫秒的延迟。如果不想要该延迟，把topic.metadata.refresh.interval.ms值改为-1，这样只有在发送失败时，才会重新刷新。 * Kafka的集群中如果某个partition所在的broker挂了，可以检查错误后重启重新加入集群，手动做rebalance，producer的连接会再次断掉，直到rebalance完成，那么刷新后取到的连接着中就会有这个新加入的broker。 #### 序列化 Producer 端会对 record 的 key 和 value 值进行序列化操作，那么显然也会在 Consumer 端再进行相应的反序列化； Kafka 内部提供提供了序列化和反序列化算法 #### 计算 record 要发送到的 partition？ 未指定分区的情况下，默认的分区策略如下： * 如果指定了partition就用指定的，否则有一个partition方法来计算 ```java /** * computes partition for given record. * if the record has partition returns the value otherwise * calls configured partitioner class to compute the partition. */ private int partition(ProducerRecord record, byte[] serializedKey, byte[] serializedValue, Cluster cluster) { Integer partition = record.partition(); return partition != null ? partition : partitioner.partition( record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster); } ``` * 没有指明 partition 值, 但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值； * 没有指明 partition 值, 且没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值（即 round-robin 算法） ```java public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) { List partitions = cluster.partitionsForTopic(topic); int numPartitions = partitions.size(); if (keyBytes == null) {// 没有指定 key 的情况下 int nextValue = nextValue(topic); // 第一次的时候产生一个随机整数,后面每次调用在之前的基础上自增; List availablePartitions = cluster.availablePartitionsForTopic(topic); // leader 不为 null,即为可用的 partition if (availablePartitions.size() > 0) { int part = Utils.toPositive(nextValue) % availablePartitions.size(); return availablePartitions.get(part).partition(); } else { return Utils.toPositive(nextValue) % numPartitions; } } else {// 有 key 的情况下,使用 key 的 hash 值进行计算 return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions; // 选择 key 的 hash 值 } } // 根据 topic 获取对应的整数变量 private int nextValue(String topic) { AtomicInteger counter = topicCounterMap.get(topic); if (null == counter) { // 第一次调用时，随机产生 counter = new AtomicInteger(new Random().nextInt()); AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter); if (currentCounter != null) { counter = currentCounter; } } return counter.getAndIncrement(); // 后面再调用时，根据之前的结果自增 } ``` 当然也可以自己实现`Partitioner`接口 accumulator.append() RecordAccumulator /** * This class acts as a queue that accumulates records into {@link MemoryRecords} * instances to be sent to the server. * * The accumulator uses a bounded amount of memory and append calls will block when that memory is exhausted, unless * this behavior is explicitly disabled. */ public final class RecordAccumulator { private final Logger log; // RecordAccumulator是否关闭的标志位closed private volatile boolean closed; // flushes过程计数器flushesInProgress private final AtomicInteger flushesInProgress; // appends过程计数器appendsInProgress private final AtomicInteger appendsInProgress; // 批量大小batchSize private final int batchSize; // 压缩器类型CompressionType实例compression private final CompressionType compression; // 延迟时间lingerMs private final long lingerMs; // 重试时间retryBackoffMs private final long retryBackoffMs; // 缓冲池BufferPool类型的free private final BufferPool free; private final Time time; private final ApiVersions apiVersions; // TopicPartition到RecordBatch双端队列的ConcurrentMap集合 private final ConcurrentMap> batches; // 处于完成状态的批量记录IncompleteRecordBatches类型的incomplete private final IncompleteBatches incomplete; // The following variables are only accessed by the sender thread, so we don't need to protect them. private final Set muted; private int drainIndex; private final TransactionManager transactionManager; append方法的源码流程 /** * Add a record to the accumulator, return the append result * * The append result will contain the future metadata, and flag for whether the appended batch is full or a new batch is created * * * @param tp The topic/partition to which this record is being sent * @param timestamp The timestamp of the record * @param key The key for the record * @param value The value for the record * @param headers the Headers for the record * @param callback The user-supplied callback to execute when the request is complete * @param maxTimeToBlock The maximum time in milliseconds to block for buffer memory to be available */ public RecordAppendResult append(TopicPartition tp, long timestamp, byte[] key, byte[] value, Header[] headers, Callback callback, long maxTimeToBlock) throws InterruptedException { // We keep track of the number of appending thread to make sure we do not miss batches in // abortIncompleteBatches(). appendsInProgress.incrementAndGet(); ByteBuffer buffer = null; if (headers == null) headers = Record.EMPTY_HEADERS; try { /** * 获取(或创建)对应的deque */ // check if we have an in-progress batch Deque dq = getOrCreateDeque(tp); synchronized (dq) { if (closed) throw new IllegalStateException(\"Cannot send after the producer is closed.\"); /** * 尝试往队列添加数据 * 数据需要添加到`ProducerBatch`中，需要内存;第一次还没有`ProducerBatch`，会失败 */ RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq); if (appendResult != null) return appendResult; } /** * 计算一个`ProducerBatch`的大小，从`BufferPool`线程池中申请,默认的batchSize=16k * 如果一个record的大小超过了一个batchSize，那么一个record就是一个`ProducerBatch`,数据一条一条的发送 */ // we don't have an in-progress record batch try to allocate a new batch byte maxUsableMagic = apiVersions.maxUsableProduceMagic(); int size = Math.max(this.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers)); log.trace(\"Allocating a new {} byte message buffer for topic {} partition {}\", size, tp.topic(), tp.partition()); buffer = free.allocate(size, maxTimeToBlock); synchronized (dq) { // Need to check if producer is closed again after grabbing the dequeue lock. if (closed) throw new IllegalStateException(\"Cannot send after the producer is closed.\"); /** * 继续尝试添加到`ProducerBatch`中 * 第一次申请的内存还没有生成一个`ProducerBatch`,所以append还是会失败 */ RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq); if (appendResult != null) { // Somebody else found us a batch, return the one we waited for! Hopefully this doesn't happen often... return appendResult; } /** * 去创建`ProducerBatch` */ MemoryRecordsBuilder recordsBuilder = recordsBuilder(buffer, maxUsableMagic); ProducerBatch batch = new ProducerBatch(tp, recordsBuilder, time.milliseconds()); /** * 继续尝试添加到`ProducerBatch`中 */ FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, headers, callback, time.milliseconds())); /** * `ProducerBatch`放到deque的尾部 */ dq.addLast(batch); incomplete.add(batch); // Don't deallocate this buffer in the finally block as it's being used in the record batch buffer = null; return new RecordAppendResult(future, dq.size() > 1 || batch.isFull(), true); } } finally { if (buffer != null) free.dea llocate(buffer); appendsInProgress.decrementAndGet(); } } sender线程处理流程 注：在new KafkaProducer<>(props);的时候会启动sender线程 sender源码 Sender run sendProducerData Cluster cluster = metadata.fetch(); this.accumulator.ready(cluster, now); Map> batches = this.accumulator.drain sensors.updateProduceRequestMetrics(batches); sendProduceRequests(batches, now); client.poll(pollTimeout, now); metadataUpdater.maybeUpdate(now); NetworkClient maybeUpdate() this.selector.poll(Utils.min(timeout, metadataTimeout, requestTimeoutMs)); sendProducerData private long sendProducerData(long now) { /** * 获取到当前的集群信息 */ Cluster cluster = metadata.fetch(); /** * 获取当前准备发送的partition(每个partition有一个leader broker， 没有则要更新元数据信息) * * ready方法返回 * 1. 哪些TopicPartition所对应的Node节点是可以发送信息的。 * 2. 下次检查节点是否ready的时间。 * 3. 哪些TopicPartition对应的leader找不到。 */ // get the list of partitions with data ready to send RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(cluster, now); // if there are any partitions whose leaders are not known yet, force metadata update if (!result.unknownLeaderTopics.isEmpty()) { // The set of topics with unknown leader contains topics with leader election pending as well as // topics which may have expired. Add the topic again to metadata to ensure it is included // and request metadata update, since there are messages to send to the topic. for (String topic : result.unknownLeaderTopics) this.metadata.add(topic); this.metadata.requestUpdate(); } /** * NetworkClient检查broker leader网络连接情况，不符合条件的Node将从readyNodes中移除 */ // remove any nodes we aren't ready to send to Iterator iter = result.readyNodes.iterator(); long notReadyTimeout = Long.MAX_VALUE; while (iter.hasNext()) { Node node = iter.next(); if (!this.client.ready(node, now)) { iter.remove(); notReadyTimeout = Math.min(notReadyTimeout, this.client.connectionDelay(node, now)); } } /** * 上面确定了哪些broker leader是可以发送数据的，调用RecordAccumulator.drain()方法，获取待发送的消息集合 * 返回的一个map结构，并设置TopicPartition为muted */ // create produce requests Map> batches = this.accumulator.drain(cluster, result.readyNodes, this.maxRequestSize, now); if (guaranteeMessageOrder) { // Mute all the partitions drained for (List batchList : batches.values()) { for (ProducerBatch batch : batchList) this.accumulator.mutePartition(batch.topicPartition); } } /** * 判断过期的ProducerBatch，再调用failBatch()方法：会调用 ProducerBatch 的done()方法去释放空间 */ List expiredBatches = this.accumulator.expiredBatches(this.requestTimeout, now); // Reset the producer id if an expired batch has previously been sent to the broker. Also update the metrics // for expired batches. see the documentation of @TransactionState.resetProducerId to understand why // we need to reset the producer id here. if (!expiredBatches.isEmpty()) log.trace(\"Expired {} batches in accumulator\", expiredBatches.size()); for (ProducerBatch expiredBatch : expiredBatches) { failBatch(expiredBatch, -1, NO_TIMESTAMP, expiredBatch.timeoutException(), false); if (transactionManager != null && expiredBatch.inRetry()) { // This ensures that no new batches are drained until the current in flight batches are fully resolved. transactionManager.markSequenceUnresolved(expiredBatch.topicPartition); } } sensors.updateProduceRequestMetrics(batches); // If we have any nodes that are ready to send + have sendable data, poll with 0 timeout so this can immediately // loop and try sending more data. Otherwise, the timeout is determined by nodes that have partitions with data // that isn't yet sendable (e.g. lingering, backing off). Note that this specifically does not include nodes // with sendable data that aren't ready to send since they would cause busy looping. long pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout); if (!result.readyNodes.isEmpty()) { log.trace(\"Nodes with data ready to send: {}\", result.readyNodes); // if some partitions are already ready to be sent, the select time would be 0; // otherwise if some partition already has some data accumulated but not ready yet, // the select time will be the time difference between now and its linger expiry time; // otherwise the select time will be the time difference between now and the metadata expiry time; pollTimeout = 0; } /** * 会封装成ClientRequest，发送到NetworkClient,再调用NetworkClient.send()将ClientRequest写入KafkaChannel的send字段 */ sendProduceRequests(batches, now); return pollTimeout; } 超时消息的处理 /** * 判断过期的ProducerBatch，再调用failBatch()方法 * 会调用 ProducerBatch 的done()方法结束request * 会调用 accumulator.deallocate 去释放内存 */ List expiredBatches = this.accumulator.expiredBatches(this.requestTimeout, now); // Reset the producer id if an expired batch has previously been sent to the broker. Also update the metrics // for expired batches. see the documentation of @TransactionState.resetProducerId to understand why // we need to reset the producer id here. if (!expiredBatches.isEmpty()) log.trace(\"Expired {} batches in accumulator\", expiredBatches.size()); for (ProducerBatch expiredBatch : expiredBatches) { failBatch(expiredBatch, -1, NO_TIMESTAMP, expiredBatch.timeoutException(), false); if (transactionManager != null && expiredBatch.inRetry()) { // This ensures that no new batches are drained until the current in flight batches are fully resolved. transactionManager.markSequenceUnresolved(expiredBatch.topicPartition); } } /** * Get a list of batches which have been sitting in the accumulator too long and need to be expired. */ public List expiredBatches(int requestTimeout, long now) { List expiredBatches = new ArrayList<>(); for (Map.Entry> entry : this.batches.entrySet()) { Deque dq = entry.getValue(); TopicPartition tp = entry.getKey(); // We only check if the batch should be expired if the partition does not have a batch in flight. // This is to prevent later batches from being expired while an earlier batch is still in progress. // Note that `muted` is only ever populated if `max.in.flight.request.per.connection=1` so this protection // is only active in this case. Otherwise the expiration order is not guaranteed. if (!muted.contains(tp)) { synchronized (dq) { // iterate over the batches and expire them if they have been in the accumulator for more than requestTimeOut ProducerBatch lastBatch = dq.peekLast(); Iterator batchIterator = dq.iterator(); while (batchIterator.hasNext()) { ProducerBatch batch = batchIterator.next(); boolean isFull = batch != lastBatch || batch.isFull(); // Check if the batch has expired. Expired batches are closed by maybeExpire, but callbacks // are invoked after completing the iterations, since sends invoked from callbacks // may append more batches to the deque being iterated. The batch is deallocated after // callbacks are invoked. /** * 判断是否超时，并从deque中删除 */ if (batch.maybeExpire(requestTimeout, retryBackoffMs, now, this.lingerMs, isFull)) { expiredBatches.add(batch); batchIterator.remove(); } else { // Stop at the first batch that has not expired. break; } } } } } return expiredBatches; } /** * A batch whose metadata is not available should be expired if one of the following is true: * * the batch is not in retry AND request timeout has elapsed after it is ready (full or linger.ms has reached). * the batch is in retry AND request timeout has elapsed after the backoff period ended. * * This methods closes this batch and sets {@code expiryErrorMessage} if the batch has timed out. */ boolean maybeExpire(int requestTimeoutMs, long retryBackoffMs, long now, long lingerMs, boolean isFull) { /** * requestTimeoutMs 请求发送超时时间，默认 30s * now 当前时间 * this.lastAppendTime ProducerBatch 创建的时间（也即上一次重试的时间） * now - this.lastAppendTime 大于 requestTimeoutMs 则说明 当前 ProducerBatch 超时了，还未发送出去 * lingerMs ProducerBatch最多等待的时间一定要发送出去，默认：100ms * retryBackoffMs 重试的时间间隔 * * 没设置重试，并且发送批次（batch.size）满了，并且配置请求超时时间（request.timeout.ms）小于【当前时间减去最后追加批次的时间】 * 没设置重试，并且 request.timeout.ms 小于【创建批次时间减去配置的等待发送的时间（linger.ms）】 * 设置重试，并且 request.timeout.ms 小于【当前时间-最后重试时间-重试需要等待的时间（retry.backoff.ms）】 */ if (!this.inRetry() && isFull && requestTimeoutMs client.poll 调用NetworkClient.poll()方法，将KafkaChannel.send字段中保存的ClientRequest发送出去，并且还会处理服务端发回的响应、处理超时的请求、调用用户自定义的CallBack NetworkClient.poll() /** * Do actual reads and writes to sockets. * * @param timeout The maximum amount of time to wait (in ms) for responses if there are none immediately, * must be non-negative. The actual timeout will be the minimum of timeout, request timeout and * metadata timeout * @param now The current time in milliseconds * @return The list of responses received */ @Override public List poll(long timeout, long now) { if (!abortedSends.isEmpty()) { // If there are aborted sends because of unsupported version exceptions or disconnects, // handle them immediately without waiting for Selector#poll. List responses = new ArrayList<>(); handleAbortedSends(responses); completeResponses(responses); return responses; } long metadataTimeout = metadataUpdater.maybeUpdate(now); try { this.selector.poll(Utils.min(timeout, metadataTimeout, requestTimeoutMs)); } catch (IOException e) { log.error(\"Unexpected error during I/O\", e); } // process completed actions long updatedNow = this.time.milliseconds(); List responses = new ArrayList<>(); handleCompletedSends(responses, updatedNow); handleCompletedReceives(responses, updatedNow); handleDisconnections(responses, updatedNow); handleConnections(); handleInitiateApiVersionRequests(updatedNow); handleTimedOutRequests(responses, updatedNow); completeResponses(responses); return responses; } selector poll /** * Do whatever I/O can be done on each connection without blocking. This includes completing connections, completing * disconnections, initiating new sends, or making progress on in-progress sends or receives. * * When this call is completed the user can check for completed sends, receives, connections or disconnects using * {@link #completedSends()}, {@link #completedReceives()}, {@link #connected()}, {@link #disconnected()}. These * lists will be cleared at the beginning of each `poll` call and repopulated by the call if there is * any completed I/O. * * In the \"Plaintext\" setting, we are using socketChannel to read & write to the network. But for the \"SSL\" setting, * we encrypt the data before we use socketChannel to write data to the network, and decrypt before we return the responses. * This requires additional buffers to be maintained as we are reading from network, since the data on the wire is encrypted * we won't be able to read exact no.of bytes as kafka protocol requires. We read as many bytes as we can, up to SSLEngine's * application buffer size. This means we might be reading additional bytes than the requested size. * If there is no further data to read from socketChannel selector won't invoke that channel and we've have additional bytes * in the buffer. To overcome this issue we added \"stagedReceives\" map which contains per-channel deque. When we are * reading a channel we read as many responses as we can and store them into \"stagedReceives\" and pop one response during * the poll to add the completedReceives. If there are any active channels in the \"stagedReceives\" we set \"timeout\" to 0 * and pop response and add to the completedReceives. * * Atmost one entry is added to \"completedReceives\" for a channel in each poll. This is necessary to guarantee that * requests from a channel are processed on the broker in the order they are sent. Since outstanding requests added * by SocketServer to the request queue may be processed by different request handler threads, requests on each * channel must be processed one-at-a-time to guarantee ordering. * * @param timeout The amount of time to wait, in milliseconds, which must be non-negative * @throws IllegalArgumentException If `timeout` is negative * @throws IllegalStateException If a send is given for which we have no existing connection or for which there is * already an in-progress send */ @Override public void poll(long timeout) throws IOException { if (timeout = 0\"); boolean madeReadProgressLastCall = madeReadProgressLastPoll; clear(); boolean dataInBuffers = !keysWithBufferedRead.isEmpty(); if (hasStagedReceives() || !immediatelyConnectedKeys.isEmpty() || (madeReadProgressLastCall && dataInBuffers)) timeout = 0; if (!memoryPool.isOutOfMemory() && outOfMemory) { //we have recovered from memory pressure. unmute any channel not explicitly muted for other reasons log.trace(\"Broker no longer low on memory - unmuting incoming sockets\"); for (KafkaChannel channel : channels.values()) { if (channel.isInMutableState() && !explicitlyMutedChannels.contains(channel)) { channel.unmute(); } } outOfMemory = false; } /* check ready keys */ long startSelect = time.nanoseconds(); int numReadyKeys = select(timeout); long endSelect = time.nanoseconds(); this.sensors.selectTime.record(endSelect - startSelect, time.milliseconds()); if (numReadyKeys > 0 || !immediatelyConnectedKeys.isEmpty() || dataInBuffers) { Set readyKeys = this.nioSelector.selectedKeys(); // Poll from channels that have buffered data (but nothing more from the underlying socket) if (dataInBuffers) { keysWithBufferedRead.removeAll(readyKeys); //so no channel gets polled twice Set toPoll = keysWithBufferedRead; keysWithBufferedRead = new HashSet<>(); //poll() calls will repopulate if needed pollSelectionKeys(toPoll, false, endSelect); } // Poll from channels where the underlying socket has more data pollSelectionKeys(readyKeys, false, endSelect); // Clear all selected keys so that they are included in the ready count for the next select readyKeys.clear(); pollSelectionKeys(immediatelyConnectedKeys, true, endSelect); immediatelyConnectedKeys.clear(); } else { madeReadProgressLastPoll = true; //no work is also \"progress\" } long endIo = time.nanoseconds(); this.sensors.ioTime.record(endIo - endSelect, time.milliseconds()); // we use the time at the end of select to ensure that we don't close any connections that // have just been processed in pollSelectionKeys maybeCloseOldestConnection(endSelect); // Add to completedReceives after closing expired connections to avoid removing // channels with completed receives until all staged receives are completed. addToCompletedReceives(); } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-12-20 12:58:43 "},"content/producer2.html":{"url":"content/producer2.html","title":"如何处理粘包/拆包问题","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 如何处理粘包/拆包问题？ Kafka处理粘包和拆包 粘包和拆包原因 NetworkReceive 如何处理粘包/拆包问题？ Kafka处理粘包和拆包 粘包和拆包原因 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包； 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包； 要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包； 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。即TCP报文长度-TCP头部长度>MSS。 NetworkReceive NetworkReceive，网络接收到的消息的对象：接收的字节大小 加上 具体大小的内容 /** * A size delimited Receive that consists of a 4 byte network-ordered size N followed by N bytes of content */ public class NetworkReceive implements Receive { // Need a method to read from ReadableByteChannel because BlockingChannel requires read with timeout // See: http://stackoverflow.com/questions/2866557/timeout-for-socketchannel-doesnt-work // This can go away after we get rid of BlockingChannel @Deprecated public long readFromReadableChannel(ReadableByteChannel channel) throws IOException { int read = 0; // size 初始值4字节：this.size = ByteBuffer.allocate(4); if (size.hasRemaining()) { int bytesRead = channel.read(size); if (bytesRead maxSize) throw new InvalidReceiveException(\"Invalid receive (size = \" + receiveSize + \" larger than \" + maxSize + \")\"); requestedBufferSize = receiveSize; //may be 0 for some payloads (SASL) if (receiveSize == 0) { buffer = EMPTY_BUFFER; } } } if (buffer == null && requestedBufferSize != -1) { //we know the size we want but havent been able to allocate it yet // 再分配内存 buffer = memoryPool.tryAllocate(requestedBufferSize); if (buffer == null) log.trace(\"Broker low on memory - could not allocate buffer of size {} for source {}\", requestedBufferSize, source); } if (buffer != null) { int bytesRead = channel.read(buffer); if (bytesRead 什么时候读完？ @Override public boolean complete() { return !size.hasRemaining() && buffer != null && !buffer.hasRemaining(); } 读不到，并且buffer里面也都被读完了，那么就表示网络消息都读取完成了 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-12-10 10:39:10 "},"content/broker.html":{"url":"content/broker.html","title":"kafka broker 理论知识","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Broker 存储文件 索引的稀疏存储（类似跳表） leader选举 Kafka Controller 选举 partition leader选举的触发 如何选举出 partition leader？ ISR HW LEO（leader follower的木桶理论/短板理论） High Watermark的更新 kafka集群怎么读取/写入数据到指定的broker分区，从指定broker的offset开始消费？ Zookeeper 在 Kafka 中的作用 Broker注册 Topic注册 生产者负载均衡 消费者负载均衡 分区 与 消费者 的关系 消费进度Offset 记录(1.0之前的版本) broker处理源码 通信协议 Broker 存储文件 log默认保留168小时(7天)，默认一个segment文件大小1G，否则产生新文件 .log存储数据 .index存储索引(类似跳表的索引) ############################# Log Retention Policy ############################# # The following configurations control the disposal of log segments. The policy can # be set to delete segments after a period of time, or after a given size has accumulated. # A segment will be deleted whenever *either* of these criteria are met. Deletion always happens # from the end of the log. # The minimum age of a log file to be eligible for deletion due to age log.retention.hours=168 # A size-based retention policy for logs. Segments are pruned from the log unless the remaining # segments drop below log.retention.bytes. Functions independently of log.retention.hours. #log.retention.bytes=1073741824 # The maximum size of a log segment file. When this size is reached a new log segment will be created. log.segment.bytes=1073741824 # The interval at which log segments are checked to see if they can be deleted according # to the retention policies log.retention.check.interval.ms=300000 索引的稀疏存储（类似跳表） 为数据文件建索引采取了稀疏存储：每隔一定字节的数据建立一条索引（这样的目的是为了减少索引文件的大小） leader选举 leader选举借助zookeeper最简单最直观的方案是:leader在zk上创建一个临时节点，所有Follower对此节点注册监听，当leader宕机时，此时ISR里的所有Follower都尝试创建该节点，而创建成功者（Zookeeper保证只有一个能创建成功）即是新的Leader，其它Replica即为Follower。 缺点：当kafka集群业务很多，partition达到成千上万时，当broker宕机时，造成集群内大量的调整，会造成大量Watch事件被触发，Zookeeper负载会过重，而zk是不适合大量写操作的。 kafka在所有broker中选出一个controller，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式（比Zookeeper Queue的方式更高效）通知需为此作出响应的Broker。同时controller也负责增删Topic以及Replica的重新分配。 Kafka Controller 选举 Kafka Controller的选举是依赖Zookeeper来实现的，在Kafka集群中哪个broker能够成功创建/controller这个临时（EPHEMERAL）节点,就可以成为Kafka Controller。 controller实现如上功能： brokers列表：ls /brokers/ids 某个broker信息：get /brokers/ids/0 topic信息：get /brokers/topics/kafka10-topic-20170924 partition信息：get /brokers/topics/kafka10-topic-20170924/partitions/0/state controller中心节点变更次数：get /controller_epoch conrtoller leader信息：get /controller partition leader选举的触发 当创建分区（创建主题或增加分区都有创建分区的动作）或分区上线（比如分区中原先的leader副本下线，此时分区需要选举一个新的leader上线来对外提供服务）的时候都需要执行leader的选举动作。还有分区进行重分配（reassign）的时候也需要执行leader的选举动作。 如何选举出 partition leader？ 不同场景下的选举思路不同；基本思路如下 按照AR集合中副本的顺序查找第一个存活的副本，并且这个副本在ISR集合中。 一个分区的AR集合在分配的时候就被指定，并且只要不发生重分配的情况，集合内部副本的顺序是保持不变的，而分区的ISR集合中副本的顺序可能会改变。注意这里是根据AR的顺序而不是ISR的顺序进行选举的。 分区进行重分配（reassign）的时候也需要执行leader的选举动作。 思路：从重分配的AR列表中找到第一个存活的副本，且这副本在目前的ISR列表中。 发生优先副本（preferred replica partition leader election）的选举时，直接将优先副本设置为leader即可，AR集合中的第一个副本即为优先副本。 当某节点被优雅地关闭（也就是执行ControlledShutdown）时，位于这个节点上的leader副本都会下线，所以与此对应的分区需要执行leader的选举。从AR列表中找到第一个存活的副本，且这个副本在目前的ISR列表中，与此同时还要确保这个副本不处于正在被关闭的节点上。 ISR 分区中的所有副本统称为AR（Assigned Repllicas）。 所有与leader副本保持一定程度同步的副本（包括Leader）组成ISR（In-Sync Replicas），ISR集合是AR集合中的一个子集。 ISR集合的副本必须满足：副本所在节点必须维持着与zookeeper的连接；副本最后一条消息的offset与leader副本最后一条消息的offset之间的差值不能超出指定的阈值 每个分区的leader副本都会维护此分区的ISR集合，写请求首先由leader副本处理，之后follower副本会从leader副本上拉取写入的消息，这个过程会有一定的延迟，导致follower副本中保存的消息略少于leader副本，只要未超出阈值都是可以容忍的 HW LEO（leader follower的木桶理论/短板理论） HW （High Watermark）俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。 LEO （Log End Offset），标识当前日志文件中下一条待写入的消息的offset。LEO 的大小相当于当前日志分区中最后一条消息的offset值加1. 分区 ISR 集合中的每个副本都会维护自身的 LEO ，而 ISR 集合中最小的 LEO 即为分区的 HW，对消费者而言只能消费 HW 之前的消息。 leader LEO：leader的LEO就保存在其所在的broker的缓存里，当leader副本log文件写入消息后，就会更新自己的LEO remote LEO和follower LEO：remote LEO是保存在leader副本上的follower副本的LEO，可以看出leader副本上保存所有副本的LEO，当然也包括自己的。follower LEO就是follower副本的LEO 如果是remote LEO，更新前leader需要确认follower的fetch请求包含的offset，这个offset就是follower副本的LEO，根据它对remote LEO进行更新。如果更新时尚未收到fetch请求，或者fetch请求在请求队列中排队，则不做更新。可以看出在leader副本给follower副本返回数据之前，remote LEO就先更新了。 如果是follower LEO，它的更新是在follower副本得到leader副本发送的数据并随后写入到log文件，就会更新自己的LEO。 High Watermark的更新 leader的HW是所有副本的最小LEO； follower的HW是从leader同步消息fetch时，leader的返回的HW与当前副本的LEO中取较小者； follower从leader同步数据，发送fetch请求 follower获取到数据后写本地磁盘 follower更新当前副本的LEO follower再次从leader同步数据，同时fetch请求里包含了自己的LEO（即把自己的LEO告诉leader） leader更新保存的follower LEO leader取所有副本最小的LEO作为HW（leader根据取短板LEO，最为最后的LEO） kafka集群怎么读取/写入数据到指定的broker分区，从指定broker的offset开始消费？ 向指定的partition发送数据 ProducerRecord new的时候可以指定partition 从指定的partition开始消费数据 consumer可以指定从特定offset开始消费数据 从指定的partition的指定的offset开始消费数据 consumer.seek可以指定 Zookeeper 在 Kafka 中的作用 Broker注册 Broker是分布式部署并且相互之间相互独立，但是需要有一个注册系统能够将整个集群中的Broker管理起来，此时就使用到了Zookeeper。在Zookeeper上会有一个专门用来进行Broker服务器列表记录的节点。 Topic注册 在Kafka中，同一个Topic的消息会被分成多个分区并将其分布在多个Broker上，这些分区信息及与Broker的对应关系也都是由Zookeeper在维护，由专门的节点来记录。 生产者负载均衡 由于同一个Topic消息会被分区并将其分布在多个Broker上，因此，生产者需要将消息合理地发送到这些分布式的Broker上，那么如何实现生产者的负载均衡，Kafka支持传统的四层负载均衡，也支持Zookeeper方式实现负载均衡。 使用Zookeeper进行负载均衡，由于每个Broker启动时，都会完成Broker注册过程，生产者会通过该节点的变化来动态地感知到Broker服务器列表的变更，这样就可以实现动态的负载均衡机制。 消费者负载均衡 与生产者类似，Kafka中的消费者同样需要进行负载均衡来实现多个消费者合理地从对应的Broker服务器上接收消息，每个消费者分组包含若干消费者，每条消息都只会发送给分组中的一个消费者，不同的消费者分组消费自己特定的Topic下面的消息，互不干扰。 分区 与 消费者 的关系 在Kafka中，规定了每个消息分区 只能被同组的一个消费者进行消费，因此，需要在 Zookeeper 上记录 消息分区 与 Consumer 之间的关系，每个消费者一旦确定了对一个消息分区的消费权力，需要将其Consumer ID 写入到 Zookeeper 对应消息分区的临时节点上 消费进度Offset 记录(1.0之前的版本) 在消费者对指定消息分区进行消息消费的过程中，需要定时地将分区消息的消费进度Offset记录到Zookeeper上，以便在该消费者进行重启或者其他消费者重新接管该消息分区的消息消费后，能够从之前的进度开始继续进行消息消费。 补充： 早期版本的 kafka 用 zk 做 meta 信息存储，consumer 的消费状态，group 的管理以及 offse t的值。考虑到zk本身的一些因素以及整个架构较大概率存在单点问题，新版本中确实逐渐弱化了zookeeper的作用。新的consumer使用了kafka内部的group coordination协议，也减少了对zookeeper的依赖。 broker处理源码 通信协议 Producer与Kafka集群：Producer需要利用ProducerRequest和TopicMetadataRequest来完成Topic元数据的查询、消息的发送 Consumer和Kafka集群：Consumer需要利用TopicMetadataRequest请求、FetchRequest请求和ConsumerMetadataRequest请求来完成Topic元数据的查询、消息的订阅、历史偏移量的查询、偏移量的提交，当前偏移量的查询 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-12-10 00:28:53 "},"content/broker_kafkaapis.html":{"url":"content/broker_kafkaapis.html","title":"kafka broker 处理请求","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 broker 处理请求 Kafka broker上对于producer发过来的消息的处理流程图 Log对象 入口：kafka.server.KafkaApis#handle kafka.server.ReplicaManager#appendRecords kafka.cluster.Partition#appendRecordsToLeader kafka.log.Log#appendAsLeader kafka.log.LogSegment#append follower 如何同步leader的数据？ broker 处理请求 Kafka broker上对于producer发过来的消息的处理流程图 Log对象 每个 replica 会对应一个 log 对象，log 对象是管理当前分区的一个单位，它会包含这个分区的所有 segment 文件（包括对应的 offset 索引和时间戳索引文件），它会提供一些增删查的方法。 在 Log 对象的初始化时，有如下的几个重要变量： nextOffsetMetadata：可以叫做下一个偏移量元数据，它包括 activeSegment 的下一条消息的偏移量，该 activeSegment 的基准偏移量及日志分段的大小； activeSegment：指的是该 Log 管理的 segments 中那个最新的 segment（这里叫做活跃的 segment），一个 Log 中只会有一个活跃的 segment，其他的 segment 都已经被持久化到磁盘了； logEndOffset：表示下一条消息的 offset，它取自 nextOffsetMetadata 的 offset，实际上就是活动日志分段的下一个偏移量。 消息追加到日志中时，是以 segment 为单位的，当 segment 的大小到达阈值大小之后，会滚动新建一个日志分段（segment）保存新的消息，而分区的消息总是追加到最新的日志分段（也就是 activeSegment）中。每个日志分段都会有一个基准偏移量（segmentBaseOffset，或者叫做 baseOffset），这个基准偏移量就是分区级别的绝对偏移量，而且这个值在日志分段是固定的。有了这个基准偏移量，就可以计算出来每条消息在分区中的绝对偏移量，最后把数据以及对应的绝对偏移量写到日志文件中。 入口：kafka.server.KafkaApis#handle /** * Handle a produce request */ def handleProduceRequest(request: RequestChannel.Request) ... // call the replica manager to append messages to the replicas replicaManager.appendRecords( timeout = produceRequest.timeout.toLong, requiredAcks = produceRequest.acks, internalTopicsAllowed = internalTopicsAllowed, isFromClient = true, entriesPerPartition = authorizedRequestInfo, responseCallback = sendResponseCallback, processingStatsCallback = processingStatsCallback) ... kafka.server.ReplicaManager#appendRecords 处理逻辑主要如下 首先判断 acks 设置是否有效（-1，0，1三个值有效），无效的话直接返回异常，不再处理； acks 设置有效的话，调用 appendToLocalLog() 方法将 records 追加到本地对应的 log 对象中； appendToLocalLog() 处理完后，如果发现 clients 设置的 acks=-1，即需要 isr 的其他的副本同步完成才能返回 response，那么就会创建一个 DelayedProduce 对象，等待 isr 的其他副本进行同步，否则的话直接返回追加的结果。 /** * Append messages to leader replicas of the partition, and wait for them to be replicated to other replicas; * the callback function will be triggered either when timeout or the required acks are satisfied; * if the callback function itself is already synchronized on some object then pass this object to avoid deadlock. */ def appendRecords(timeout: Long, requiredAcks: Short, internalTopicsAllowed: Boolean, isFromClient: Boolean, entriesPerPartition: Map[TopicPartition, MemoryRecords], responseCallback: Map[TopicPartition, PartitionResponse] => Unit, delayedProduceLock: Option[Lock] = None, processingStatsCallback: Map[TopicPartition, RecordsProcessingStats] => Unit = _ => ()) { if (isValidRequiredAcks(requiredAcks)) { val sTime = time.milliseconds // 向本地的副本 log 追加数据 val localProduceResults = appendToLocalLog(internalTopicsAllowed = internalTopicsAllowed, isFromClient = isFromClient, entriesPerPartition, requiredAcks) debug(\"Produce to local log in %d ms\".format(time.milliseconds - sTime)) val produceStatus = localProduceResults.map { case (topicPartition, result) => topicPartition -> ProducePartitionStatus( result.info.lastOffset + 1, // required offset new PartitionResponse(result.error, result.info.firstOffset, result.info.logAppendTime, result.info.logStartOffset)) // response status } processingStatsCallback(localProduceResults.mapValues(_.info.recordsProcessingStats)) if (delayedProduceRequestRequired(requiredAcks, entriesPerPartition, localProduceResults)) { // 处理 ack=-1 的情况,需要等到 isr 的 follower 都写入成功的话,才能返回最后结果 // create delayed produce operation val produceMetadata = ProduceMetadata(requiredAcks, produceStatus) val delayedProduce = new DelayedProduce(timeout, produceMetadata, this, responseCallback, delayedProduceLock) // create a list of (topic, partition) pairs to use as keys for this delayed produce operation val producerRequestKeys = entriesPerPartition.keys.map(new TopicPartitionOperationKey(_)).toSeq // try to complete the request immediately, otherwise put it into the purgatory // this is because while the delayed produce operation is being created, new // requests may arrive and hence make this operation completable. delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys) } else { // we can respond immediately val produceResponseStatus = produceStatus.mapValues(status => status.responseStatus) responseCallback(produceResponseStatus) } } else { // If required.acks is outside accepted range, something is wrong with the client // Just return an error and don't handle the request at all val responseStatus = entriesPerPartition.map { case (topicPartition, _) => topicPartition -> new PartitionResponse(Errors.INVALID_REQUIRED_ACKS, LogAppendInfo.UnknownLogAppendInfo.firstOffset, RecordBatch.NO_TIMESTAMP, LogAppendInfo.UnknownLogAppendInfo.logStartOffset) } responseCallback(responseStatus) } } acks：-1，0，1 三个值 private def isValidRequiredAcks(requiredAcks: Short): Boolean = { requiredAcks == -1 || requiredAcks == 1 || requiredAcks == 0 } acks=0，生产者成功写入消息之前不会等待来自任何服务器的响应，这种配置，提高吞吐量，但是消息存在丢失风险。 acks=1(默认)，只要集群的leader（master）收到了消息，生产者将会受到发送成功的一个响应，如果消息无撞到达首领节点（比如首领节点崩愤，新的首领还没有被选举出来），生产者会收到一个错误响应，为了避免数据丢失，生产者会重发消息。不过，如果一个没有收到消息的节点成为新首领，消息还是会丢失。这个时候的吞吐量取决于使用的是 同步发送还是异步发送。如果让发送客户端等待服务器的响应（通过调用Fututre 对象的get（）方法，显然会增加延迟（在网络上传输一个来回的延迟）。如果客户端使用回调，延迟问题就可以得到缓解，不过吞吐量还是会受发送中消息数量的限制（比如，生产者在收到服务器响应之前可以发送多少个消息）。 acks=-1，所有参与复制的节点全部收到消息的时候，生产者才会收到来自服务器的一个响应，这种模式最安全，但是吞吐量受限制，它可以保证不止一个服务器收到消息，就算某台服务器奔溃，那么整个集群还是会正产运转。 kafka.server.ReplicaManager#appendToLocalLog /** * Append the messages to the local replica logs */ private def appendToLocalLog(internalTopicsAllowed: Boolean, isFromClient: Boolean, entriesPerPartition: Map[TopicPartition, MemoryRecords], requiredAcks: Short): Map[TopicPartition, LogAppendResult] = { trace(s\"Append [$entriesPerPartition] to local log\") entriesPerPartition.map { case (topicPartition, records) => brokerTopicStats.topicStats(topicPartition.topic).totalProduceRequestRate.mark() brokerTopicStats.allTopicsStats.totalProduceRequestRate.mark() // reject appending to internal topics if it is not allowed if (Topic.isInternal(topicPartition.topic) && !internalTopicsAllowed) { (topicPartition, LogAppendResult( LogAppendInfo.UnknownLogAppendInfo, Some(new InvalidTopicException(s\"Cannot append to internal topic ${topicPartition.topic}\")))) } else { try { val partitionOpt = getPartition(topicPartition) val info = partitionOpt match { case Some(partition) => if (partition eq ReplicaManager.OfflinePartition) throw new KafkaStorageException(s\"Partition $topicPartition is in an offline log directory on broker $localBrokerId\") // 追加records到leader上 partition.appendRecordsToLeader(records, isFromClient, requiredAcks) case None => throw new UnknownTopicOrPartitionException(\"Partition %s doesn't exist on %d\" .format(topicPartition, localBrokerId)) } val numAppendedMessages = if (info.firstOffset == -1L || info.lastOffset == -1L) 0 else info.lastOffset - info.firstOffset + 1 // update stats for successfully appended bytes and messages as bytesInRate and messageInRate brokerTopicStats.topicStats(topicPartition.topic).bytesInRate.mark(records.sizeInBytes) brokerTopicStats.allTopicsStats.bytesInRate.mark(records.sizeInBytes) brokerTopicStats.topicStats(topicPartition.topic).messagesInRate.mark(numAppendedMessages) brokerTopicStats.allTopicsStats.messagesInRate.mark(numAppendedMessages) trace(\"%d bytes written to log %s-%d beginning at offset %d and ending at offset %d\" .format(records.sizeInBytes, topicPartition.topic, topicPartition.partition, info.firstOffset, info.lastOffset)) (topicPartition, LogAppendResult(info)) } catch { // NOTE: Failed produce requests metric is not incremented for known exceptions // it is supposed to indicate un-expected failures of a broker in handling a produce request case e@ (_: UnknownTopicOrPartitionException | _: NotLeaderForPartitionException | _: RecordTooLargeException | _: RecordBatchTooLargeException | _: CorruptRecordException | _: KafkaStorageException | _: InvalidTimestampException) => (topicPartition, LogAppendResult(LogAppendInfo.UnknownLogAppendInfo, Some(e))) case t: Throwable => val logStartOffset = getPartition(topicPartition) match { case Some(partition) => partition.logStartOffset case _ => -1 } brokerTopicStats.topicStats(topicPartition.topic).failedProduceRequestRate.mark() brokerTopicStats.allTopicsStats.failedProduceRequestRate.mark() error(\"Error processing append operation on partition %s\".format(topicPartition), t) (topicPartition, LogAppendResult(LogAppendInfo.unknownLogAppendInfoWithLogStartOffset(logStartOffset), Some(t))) } } } } kafka.cluster.Partition#appendRecordsToLeader Partition组件是topic在某个broker上一个副本的抽象。每个partition对象都会维护一个Replica对象，Replica对象中又维护Log对象，也就是数据目录的抽象 def appendRecordsToLeader(records: MemoryRecords, requiredAcks: Int = 0) = { val (info, leaderHWIncremented) = inReadLock(leaderIsrUpdateLock) { leaderReplicaIfLocal match { //写之前先判断该replica是否是leader，如果不是leader则没有写权限 case Some(leaderReplica) => //获取该partition的log对象 val log = leaderReplica.log.get //获取配置的minInSyncReplicas值 val minIsr = log.config.minInSyncReplicas //当前ISR的数量 val inSyncSize = inSyncReplicas.size // 如果请求的acks=-1，但是当前的ISR比配置的minInSyncReplicas还小，那要抛出错误，表示当前ISR不足 if (inSyncSize throw new NotLeaderForPartitionException(\"Leader not local for partition %s on broker %d\" .format(topicPartition, localBrokerId)) } } // some delayed operations may be unblocked after HW changed if (leaderHWIncremented) tryCompleteDelayedRequests() info } 这里的步骤总结 先判断自己是否是leader，只有leader才可以接收producer请求然后写数据 判断当前的当前的ISR数量是否比minInSyncReplicas还小，如果ISR数量小于minInSyncReplicas就抛出异常 把消息交给自己管理的Log组件处理 kafka.log.Log#appendAsLeader Log对象是对partition数据目录的抽象。管理着某个topic在某个broker的一个partition,它可能是一个leader，也可能是replica。同时，Log对象还同时管理着多个LogSegment，也就是日志的分段。 回顾kafka log文件结构： /** * Append this message set to the active segment of the log, assigning offsets and Partition Leader Epochs * * @param records The records to append * @param isFromClient Whether or not this append is from a producer * @throws KafkaStorageException If the append fails due to an I/O error. * @return Information about the appended messages including the first and last offset. */ def appendAsLeader(records: MemoryRecords, leaderEpoch: Int, isFromClient: Boolean = true): LogAppendInfo = { append(records, isFromClient, assignOffsets = true, leaderEpoch) } Log组件拿到消息后，对消息内容进行校验以及裁剪，然后设置每一条消息的offset。还会计算当前这批消息的最大时间戳是多少，即maxTimestamp，这个时间戳和日志保留时间有着密切关系 还会校验要写入的消息数量是否大于一个segment所能容纳的最大限制，这个限制和配置segment.bytes有关系 写入到segment之前还要判断如果把这些消息写入segment，会不会导致segment超出segment.bytes的大小，如果会的话，要新建一个新的segment用于日志写入 把消息传过最新活跃的LogSegment处理 def append(records: MemoryRecords, assignOffsets: Boolean = true): LogAppendInfo = { //判断消息格式是否正确.分析消息的压缩格式 val appendInfo = analyzeAndValidateRecords(records) //如果没有一条消息格式正确，直接返回 if (appendInfo.shallowCount == 0) return appendInfo //裁剪一些错误的数据 var validRecords = trimInvalidBytes(records, appendInfo) try { lock synchronized { //需要给消息分配offset的话 if (assignOffsets) { // 计算第一条消息的offset val offset = new LongRef(nextOffsetMetadata.messageOffset) appendInfo.firstOffset = offset.value val now = time.milliseconds val validateAndOffsetAssignResult = try { //给每一条消息设置offset。并且找出maxTimestamp以及maxTimestamp对于的offset LogValidator.validateMessagesAndAssignOffsets(validRecords, offset, now, appendInfo.sourceCodec, appendInfo.targetCodec, config.compact, config.messageFormatVersion.messageFormatVersion, config.messageTimestampType, config.messageTimestampDifferenceMaxMs) } catch { case e: IOException => throw new KafkaException(\"Error in validating messages while appending to log '%s'\".format(name), e) } //获取有效的记录，然后根据这些记录设置响应的返回内容 validRecords = validateAndOffsetAssignResult.validatedRecords //消息的最大时间戳和配置的messageTimestampType有关系。当前获取消息maxTimestamp时间戳的方式有两种。 //1. 根据消息的timestamp来设置时间戳 //2. 根据消息的写入时间来设置时间戳,也就是当前时间 appendInfo.maxTimestamp = validateAndOffsetAssignResult.maxTimestamp appendInfo.offsetOfMaxTimestamp = validateAndOffsetAssignResult.shallowOffsetOfMaxTimestamp appendInfo.lastOffset = offset.value - 1 if (config.messageTimestampType == TimestampType.LOG_APPEND_TIME) appendInfo.logAppendTime = now // 由于前面的操作可能导致消息压缩格式改变以及消息格式改变，因此这里还需要重新检查一下当前的每条消息大小是否超过maxMessageSize的配置大小 if (validateAndOffsetAssignResult.messageSizeMaybeChanged) { for (logEntry config.maxMessageSize) { // we record the original message set size instead of the trimmed size // to be consistent with pre-compression bytesRejectedRate recording BrokerTopicStats.getBrokerTopicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes) BrokerTopicStats.getBrokerAllTopicsStats.bytesRejectedRate.mark(records.sizeInBytes) throw new RecordTooLargeException(\"Message size is %d bytes which exceeds the maximum configured message size of %d.\" .format(logEntry.sizeInBytes, config.maxMessageSize)) } } } } else { // we are taking the offsets we are given if (!appendInfo.offsetsMonotonic || appendInfo.firstOffset config.segmentSize) { throw new RecordBatchTooLargeException(\"Message set size is %d bytes which exceeds the maximum configured segment size of %d.\" .format(validRecords.sizeInBytes, config.segmentSize)) } // 判断是否需要新建一个segment val segment = maybeRoll(messagesSize = validRecords.sizeInBytes, maxTimestampInMessages = appendInfo.maxTimestamp, maxOffsetInMessages = appendInfo.lastOffset) //调用segment的方法添加消息 segment.append(firstOffset = appendInfo.firstOffset, largestOffset = appendInfo.lastOffset, largestTimestamp = appendInfo.maxTimestamp, shallowOffsetOfMaxTimestamp = appendInfo.offsetOfMaxTimestamp, records = validRecords) updateLogEndOffset(appendInfo.lastOffset + 1) trace(\"Appended message set to log %s with first offset: %d, next offset: %d, and messages: %s\" .format(this.name, appendInfo.firstOffset, nextOffsetMetadata.messageOffset, validRecords)) //判断是否需要将消息刷盘 if (unflushedMessages >= config.flushInterval) flush() appendInfo } } catch { case e: IOException => throw new KafkaStorageException(\"I/O exception in append to log '%s'\".format(name), e) } } kafka.log.LogSegment#append LogSegment是partition目录中数据段的抽象，kafka会将一个副本中日志根据配置分段。这个LogSegment对象维护数据文件以及索引文件的信息。 def append(firstOffset: Long, largestOffset: Long, largestTimestamp: Long, shallowOffsetOfMaxTimestamp: Long, records: MemoryRecords) { if (records.sizeInBytes > 0) { trace(\"Inserting %d bytes at offset %d at position %d with largest timestamp %d at shallow offset %d\" .format(records.sizeInBytes, firstOffset, log.sizeInBytes(), largestTimestamp, shallowOffsetOfMaxTimestamp)) //记录要插入的第一条消息的物理地址，后面生成索引的时候会用到 val physicalPosition = log.sizeInBytes() if (physicalPosition == 0) rollingBasedTimestamp = Some(largestTimestamp) //判断是否可以安全写入消息 require(canConvertToRelativeOffset(largestOffset), \"largest offset in message set can not be safely converted to relative offset.\") //将消息写入到fileChannel val appendedBytes = log.append(records) trace(s\"Appended $appendedBytes to ${log.file()} at offset $firstOffset\") //随时更新segment的maxTimestampSoFar值。 // 这个时间的获取和message.timestamp.type配置有关系。可能获取当前时间作为largestTimestamp，也可能获取日志的最大timestamp作为largestTimestamp if (largestTimestamp > maxTimestampSoFar) { maxTimestampSoFar = largestTimestamp offsetOfMaxTimestamp = shallowOffsetOfMaxTimestamp } //判断是否需要追加一条索引记录。当bytesSinceLastIndexEntry大于配置的indexIntervalBytes值时会追加新的所有记录 //bytesSinceLastIndexEntry会随着消息的写入不断增加，直到生成一条新的索引记录后重置为0 //indexIntervalBytes和broker的配置有关 if (bytesSinceLastIndexEntry > indexIntervalBytes) { index.append(firstOffset, physicalPosition) timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestamp) bytesSinceLastIndexEntry = 0 } bytesSinceLastIndexEntry += records.sizeInBytes } } logSegment底层使用了FileChannel写日志,写完之后还会判断是否要更新当前logSegment的最大时间戳 每当写入消息的大小积累到一定程度时，会新插入一条索引记录。这个积累的大小和配置index.interval.bytes有关系 Java FileChannel: FileChannel是一个连接到文件的通道。除了读写操作之外，还有裁剪特定大小文件truncate()，强制将内存中的数据刷新到硬盘中force()，对通道上锁lock()等功能。零拷贝是通过java.nio.channels.FileChannel中的transferTo方法来实现的。transferTo方法底层是基于操作系统的sendfile这个system call来实现的 follower 如何同步leader的数据？ follower从leader同步数据，发送fetch请求 follower获取到数据后写本地磁盘 follower更新当前副本的LEO follower再次从leader同步数据，同时fetch请求里包含了自己的LEO（即把自己的LEO告诉leader） leader更新保存的follower LEO leader取所有副本最小的LEO作为HW（leader根据取短板LEO，最为最后的LEO） Kafka中partition replica复制机制： Kafka中每个Broker启动时都会创建一个副本管理服务(ReplicaManager)，该服务负责维护ReplicaFetcherThread与其他Broker链路连接关系，该Broker中存在多少Follower的partitions对应leader partitions分布在不同的Broker上，有多少Broker就会创建相同数量的ReplicaFetcherThread线程同步对应partition数据，Kafka中partition间复制数据是由follower(扮演consumer角色)主动向leader获取消息，follower每次读取消息都会更新HW状态。 每当Follower的partitions发生变更影响leader所在Broker变化时，ReplicaManager就会新建或销毁相应的ReplicaFetcherThread。 如何保证一致性： 当Producer发送消息到leader partition所在Broker时，首先保证leader commit消息成功，然后创建一个\"生产者延迟请求任务\"，并判断当前partition的HW是否大于等于logEndOffset，如果满足条件即表示本次Producer请求partition replicas之间数据已经一致，立即向Producer返回Ack。否则待Follower批量拉取Leader的partition消息时，同时更新Leader ISR中HW，然后检查是否满足上述条件，如果满足向Producer返回Ack Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-12-10 00:28:58 "},"content/broker_controller.html":{"url":"content/broker_controller.html","title":"controller & leader","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 kafka 的 controller 选举和 leader 选举 创建topic是partition如何分配到broker? kafka的Replica Controller leader 选举 Partition leader 选举 kafka partition状态 kafka选择分区leader算法 NoOpLeaderSelector offlinePartitionLeader reassignedPartitionLeader preferredReplicaPartitionLeader ControlledShutdownLeader 如何处理所有Replica都不工作？ kafka 的 controller 选举和 leader 选举 kafka在所有broker中选出一个controller(Controller leader)，所有Partition的Leader选举都由controller决定(Partition leader)。controller会将Leader的改变直接通过RPC的方式（比Zookeeper Queue的方式更高效）通知需为此作出响应的Broker。同时controller也负责增删Topic以及Replica的重新分配。 创建topic是partition如何分配到broker? replica assignment有三个目标： 在brokers之间均分replicas partition与它的其他replicas不再同一个broker上 如果broker有rack信息，则partition的replicas尽量分配在不同rack上面 副本因子不能大于broker的个数 第0个分区的第一个副本放置位置是随机从brokerList中选择的 其它分区的第一个副本位置是相对于第0个分区往后移动（eg: 5个broker，5个分区，如果第0分区放到了broker4上，接着第1分区放broker5, 第2分区放broker1，第3分区放broker2，第4分区放到broker3上） 剩余副本相对于第一个副本放置位置其实是有nextReplicaShift决定的，而这个数也是随机产生的 private def assignReplicasToBrokersRackUnaware(nPartitions: Int, replicationFactor: Int, brokerList: Seq[Int], fixedStartIndex: Int, startPartitionId: Int): Map[Int, Seq[Int]] = { val ret = mutable.Map[Int, Seq[Int]]() val brokerArray = brokerList.toArray val startIndex = if (fixedStartIndex >= 0) fixedStartIndex else rand.nextInt(brokerArray.length) var currentPartitionId = math.max(0, startPartitionId) var nextReplicaShift = if (fixedStartIndex >= 0) fixedStartIndex else rand.nextInt(brokerArray.length) for (_ 0 && (currentPartitionId % brokerArray.length == 0)) nextReplicaShift += 1 val firstReplicaIndex = (currentPartitionId + startIndex) % brokerArray.length val replicaBuffer = mutable.ArrayBuffer(brokerArray(firstReplicaIndex)) for (j kafka的Replica kafka的Replica kafka的topic可以设置有N个副本（replica），副本数最好要小于broker的数量，也就是要保证一个broker上的replica最多有一个，所以可以用broker id指定Partition replica。 创建副本的单位是topic的分区，每个分区有1个leader和0到多个follower，我们把多个replica分为Lerder replica和follower replica。 当producer在向partition中写数据时，根据ack机制，默认ack=1，只会向leader中写入数据，然后leader中的数据会复制到其他的replica中，follower会周期性的从leader中pull数据，但是对于数据的读写操作都在leader replica中，follower副本只是当leader副本挂了后才重新选取leader，follower并不向外提供服务。 kafka不是完全同步，也不是完全异步，是一种特殊的ISR（In Sync Replica） leader会维持一个与其保持同步的replica集合，该集合就是ISR，每一个partition都有一个ISR，由leader动态维护。 我们要保证kafka不丢失message，就要保证ISR这组集合存活（至少有一个存活），并且消息commit成功。 分布式消息系统对一个节点是否存活有这样两个条件判断： 第一个，节点必须维护和zookeeper的连接，zookeeper通过心跳机制检查每个节点的连接； 第二个，如果节点时follower，它必要能及时同步与leader的写操作，不是延时太久。 Controller leader 选举 当broker启动的时候，都会创建KafkaController对象，但是集群中只能有一个leader对外提供服务，这些每个节点上的KafkaController会在指定的zookeeper路径下创建临时节点，只有第一个成功创建的节点的KafkaController才可以成为leader，其余的都是follower。当leader故障后，所有的follower会收到通知，再次竞争在该路径下创建节点从而选举新的leader 实际上的实现思路如上，只是优化了下，多了个代理控制管理类（controller）。引入的原因是，当kafka集群业务很多，partition达到成千上万时，当broker宕机时，造成集群内大量的调整，会造成大量Watch事件被触发，Zookeeper负载会过重。而zk是不适合大量写操作的。 Partition leader 选举 由controller leader执行 从Zookeeper中读取当前分区的所有ISR(in-sync replicas)集合 调用配置的分区选择算法选择分区的leader kafka partition状态 NonExistentPartition：这个状态表示该分区要么没有被创建过或曾经被创建过但后面被删除了。 NewPartition：分区创建之后就处于NewPartition状态。在这个状态中，分区应该已经分配了副本，但是还没有选举出leader和ISR。 OnlinePartition：一旦分区的leader被推选出来，它就处于OnlinePartition状态。 OfflinePartition：如果leader选举出来后，leader broker宕机了，那么该分区就处于OfflinePartition状态。 kafka选择分区leader算法 NoOpLeaderSelector 不做任何事情，仅仅返回下当前的Leader，ISR，AR offlinePartitionLeader 当KafkaController尝试将分区状态从OfflinePartition或者NewPartion切换为OnlinePartition的时候会使用这种策略。 筛选出在线的ISR和在线的AR 优先在在线的ISR中选择，在线的ISR列表不为空，则选择在线ISR列表中的第一个，结束选举 在线的ISR为空，则根据unclean.leader.election.enable的配置是否在在线的AR列表中选择，unclean.leader.election.enable代表了是否允许不在ISR列表中选举Leader，默认为true，如果为true，则选择在线AR中的第一个，结束选举；如果AR列表为空，则选举失败。 reassignedPartitionLeader 随着Topic的新建和删除以及Broker Server的上下线，原本Topic分区的AR列表在集群中的分布变得越来越不均匀了，此时如果管理员下发分区重分配的指令，就会在Zookeeper的/admin/reassgin_partitions目录下指定Topic分区的AR列表，此时Leader状态的KafkaController检测到这个路径的数据变化，会触发相应的回调函数，使得对应的Topic分区发生Leader Replica的选举 获取指定的AR列表 针对指定的AR列表，在线的Broker Server和当前的ISR列表求交集 如果交集不为空，则选举成功，其第一个Replica即为新的leader；否则选举失败。 preferredReplicaPartitionLeader 获取指定的AR列表 选择第一额Replica作为特定的Leader Replica 判断待定的Leader Replica是否在在线的Broker Server中和当前的ISR列表中，如果是，则选举成功，其第一个Replica即成为Leader；否则选举失败 ControlledShutdownLeader 当Broker Server下线的时候会向Leader状态的KafkaController下发ContolledShutdownRequest的指令，KafkaController接收到该指令之后会针对位于该Broker Server上的Leader Replica的分区重新进行Leader replica选举 获取分区的ISR列表 在SIT列表中剔除离线的Replica作为新的ISR列表 如果新的ISR列表不为空，则选举成功，其第一个Replica即为新的Leader；否则选举失败 如何处理所有Replica都不工作？ 在ISR中至少有一个follower时，Kafka可以确保已经commit的数据不丢失，但如果某个Partition的所有Replica都宕机了，就无法保证数据不丢失了。这种情况下有两种可行的方案： 等待ISR中的任一个Replica\"活\"过来，并且选它作为Leader 选择第一个\"活\"过来的Replica（不一定是ISR中的）作为Leader 这就需要在可用性和一致性当中作出一个简单的折衷。如果一定要等待ISR中的Replica“活”过来，那不可用的时间就可能会相对较长。而且如果ISR中的所有Replica都无法“活”过来了，或者数据都丢失了，这个Partition将永远不可用。选择第一个“活”过来的Replica作为Leader，而这个Replica不是ISR中的Replica，那即使它并不保证已经包含了所有已commit的消息，它也会成为Leader而作为consumer的数据源（前文有说明，所有读写都由Leader完成）。Kafka0.8.*使用了第二种方式。根据Kafka的文档，在以后的版本中，Kafka支持用户通过配置选择这两种方式中的一种，从而根据不同的使用场景选择高可用性还是强一致性。 unclean.leader.election.enable 参数决定使用哪种方案，默认是true，采用第二种方案 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-12-09 23:44:20 "},"content/consumer.html":{"url":"content/consumer.html","title":"constumer","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Consumer consumer采用pull（拉）模式从broker中读取数据？ Consumer Group(消费组) 同一个 Topic 可以多个消费组 再均衡（Rebalance） 再均衡策略(默认:Range) 再均衡影响 消费者数据的不丢失？ offset的维护（zookeeper维护） offset的维护（内置topic_consumeroffsets维护） 计算消息提交到_consumeroffsets哪个分区? 提交offset 同步提交offset 异步提交offset 异步+同步 组合的方式提交偏移量 低级消费者(或简单消费者) 高级消费者 Consumer consumer采用pull（拉）模式从broker中读取数据？ push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。 pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直返回空数据。针对这一点，Kafka的消费者在消费数据时会传入一个时长参数timeout，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，这段时长即为timeout Consumer Group(消费组) consumer group是kafka提供的可扩展且具有容错性的消费者机制 一个消费组可以有多个消费者或消费者实例(consumer instance) 一个消费组下的所有消费者共享一个公共的ID，即group ID 一个消费组下订阅的topic下的每个partition只能分配给该group下的一个consumer(当然该分区还可以被分配给其他group)，即一个partition只能被一个消费进程/线程消费，而不能被多个消费进程/线程消费(当然一个消费进程/线程可以消费多个partition) 每一个消费组都会被记录它在某一个分区的Offset，即不同consumer group针对同一个分区，都有\"各自\"的偏移量 同一个 Topic 可以多个消费组 再均衡（Rebalance） 再平衡，指的是在kafka consumer所订阅的topic发生变化时发生的一种分区重分配机制。一般有三种情况会触发再平衡： consumer group中的新增或删除某个consumer，导致其所消费的分区需要分配到组内其它的consumer上； consumer订阅的topic发生变化，比如订阅的topic采用的是正则表达式的形式，如test-*，此时如果有一个新建了一个topic:test-user过来，那么这个topic的所有分区也是会自动分配给当前的consumer的，此时就会发生再平衡； consumer所订阅的topic发生了新增partition的行为，那么新增的分区就会分配给当前的consumer，此时就会触发再平衡。 eg:有一个 Topic 有4个分区，有一个消费者组订阅了这个 Topic，随着组中的消费者数量从1个增加到5个时，Topic 中分区被读取的情况如下 所以：一个消费组中 consumer 的数量超过分区数，多出的 consumer 会被闲置。因此，如果想提高消费者的并行处理能力，需要设置足够多的 partition 数量 再均衡策略(默认:Range) Round Robin：会采用轮询的方式将当前所有的分区依次分配给所有的consumer； Range：首先会计算每个consumer可以消费的分区个数，然后按照顺序将指定个数范围的分区分配给各个consumer； Sticky：这种分区策略是最新版本中新增的一种策略，其主要实现了两个目的： -- 将现有的分区尽可能均衡的分配给各个consumer，存在此目的的原因在于Round Robin和Range分配策略实际上都会导致某几个consumer承载过多的分区，从而导致消费压力不均衡； -- 如果发生再平衡，那么在重新分配前的基础上会尽力保证当前未宕机的consumer所消费的分区不会被分配给其它的consumer上； 再均衡影响 Rebalance本身是Kafka集群的一个保护设定，用于剔除掉无法消费或者过慢的消费者，然后由于我们的数据量较大，同时后续消费后的数据写入需要走网络IO，很有可能存在依赖的第三方服务存在慢的情况而导致我们超时。 Rebalance对我们数据的影响主要有以下几点： 数据重复消费: 消费过的数据由于提交offset任务也会失败，在partition被分配给其它消费者的时候，会造成重复消费，数据重复且增加集群压力 Rebalance扩散到整个ConsumerGroup的所有消费者，因为一个消费者的退出，导致整个Group进行了Rebalance，并在一个比较慢的时间内达到稳定状态，影响面较大 频繁的Rebalance反而降低了消息的消费速度，大部分时间都在重复消费和Rebalance 数据不能及时消费，会累积lag，在Kafka的TTL之后会丢弃数据 消费者数据的不丢失？ 通过offset commit来保证数据的不丢失。kafka自己记录了每次消费的offset数值，下次消费的时候从上次的offset继续消费 而offset的信息在kafka0.9版本之前保存在zookeeper中，在0.9版本后保存到了一个topic中，即使消费者在运行过程中挂掉了，再次启动的时候会找到offset的值，即可接着上次消费。由于offset的信息写入的时候并不是每条消息消费完成就写入，所以会导致有重复消费的问题，但是不会丢失消息 唯一例外的情况是，我们在程序中给原本做不同功能的两个consumer组设置了KafkaSpoutConfig.builder.setGroupid的时候设置成了同样的groupid,这种情况会导致这两个组共享了同一份数据，就会产生组A消费partition1，partition2中的消息，组B消费partition3的消息，这样每个组消费的消息都会丢失，都是不完整的。为了保证每个组都能独享一份消息数据，groupid一定不要重复 offset的维护（zookeeper维护） Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets offset的维护（内置topic__consumer_offsets维护） kafka在0.10.x版本后默认将消费者组的位移提交到自带的topic:__consumer_offsets里面,当有消费者第一次消费kafka数据时就会自动创建，它的副本数不受集群配置的topic副本数限制，分区数默认50（可以配置），默认压缩策略为compact key version : 版本字段，不同kafka版本的version不同 group : 对应消费者组的groupid，这条消息要发送到__consumer_offset的哪个分区,是由这个字段决定的 topic : 主题名称 partition : 主题的分区 value version : 版本字段，不同kafka版本的version不同 offset : 这个groupid消费这个topic到哪个位置了，offset的下一个值 metadata : 自定义元数据信息 commit_timestamp : 提交到kafka的时间 expire_timestamp : 过期时间, 当数据过期时会有一个定时任务去清理过期的消息 计算消息提交到__consumer_offsets哪个分区? topic:__consumer_offsets的默认分区50，消费组的offset信息究竟落到那个partition，直接hash取模如下 Math.abs(\"test\".hashCode()) % 50 = 48, 表示test这个groupid的offset记录提交到了__consumer_offset的48号分区里 提交offset offset提交的方式有两种：自动提交和手动提交。 offset下标自动提交其实在很多场景都不适用，因为自动提交是在kafka拉取到数据之后就直接提交，这样很容易丢失数据，尤其是在需要事物控制的时候。很多情况下我们需要从kafka成功拉取数据之后，对数据进行相应的处理之后再进行提交。如拉取数据之后进行写入mysql这种，所以这时我们就需要进行手动提交kafka的offset下标。 手动提交偏移量: 1. 同步提交 2. 异步提交 3. 异步+同步 组合的方式提交 同步提交offset 同步模式下提交失败的时候一直尝试提交，直到遇到无法重试的情况下才会结束，同时同步方式下消费者线程在拉取消息会被阻塞，在broker对提交的请求做出响应之前，会一直阻塞直到偏移量提交操作成功或者在提交过程中发生异常，限制了消息的吞吐量。只有当前批次的消息提交完成时才会触发poll来获取下一轮的消息。 import org.apache.kafka.clients.consumer.ConsumerRecord; import org.apache.kafka.clients.consumer.ConsumerRecords; import org.apache.kafka.clients.consumer.KafkaConsumer; import java.util.Arrays; import java.util.Properties; public class CustomComsumer { public static void main(String[] args) { Properties props = new Properties(); //Kafka集群 props.put(\"bootstrap.servers\", \"hadoop102:9092\"); //消费者组，只要group.id相同，就属于同一个消费者组 props.put(\"group.id\", \"test\"); props.put(\"enable.auto.commit\", \"false\");//关闭自动提交offset props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); KafkaConsumer consumer = new KafkaConsumer<>(props); consumer.subscribe(Arrays.asList(\"first\"));//消费者订阅主题 while (true) { //消费者拉取数据 ConsumerRecords records = consumer.poll(100); for (ConsumerRecord record : records) { System.out.printf(\"offset = %d, key = %s, value = %s%n\", record.offset(), record.key(), record.value()); } // 同步提交，当前线程会阻塞直到offset提交成功 consumer.commitSync(); } } } 异步提交offset 异步手动提交offset时，消费者线程不会阻塞，提交失败的时候也不会进行重试，并且可以配合回调函数在broker做出响应的时候记录错误信息。对于异步提交，由于不会进行失败重试，当消费者异常关闭或者触发了再均衡前，如果偏移量还未提交就会造成偏移量丢失。 import org.apache.kafka.clients.consumer.*; import org.apache.kafka.common.TopicPartition; import java.util.Arrays; import java.util.Map; import java.util.Properties; public class CustomConsumer { public static void main(String[] args) { Properties props = new Properties(); //Kafka集群 props.put(\"bootstrap.servers\", \"hadoop102:9092\"); //消费者组，只要group.id相同，就属于同一个消费者组 props.put(\"group.id\", \"test\"); //关闭自动提交offset props.put(\"enable.auto.commit\", \"false\"); props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); KafkaConsumer consumer = new KafkaConsumer<>(props); consumer.subscribe(Arrays.asList(\"first\"));//消费者订阅主题 while (true) { ConsumerRecords records = consumer.poll(100);//消费者拉取数据 for (ConsumerRecord record : records) { System.out.printf(\"offset = %d, key = %s, value = %s%n\", record.offset(), record.key(), record.value()); } //异步提交 consumer.commitAsync(new OffsetCommitCallback() { @Override public void onComplete(Map offsets, Exception exception) { if (exception != null) { System.err.println(\"Commit failed for\" + offsets); } } }); } } } 异步+同步 组合的方式提交偏移量 针对异步提交偏移量丢失的问题，通过对消费者进行异步批次提交并且在关闭时同步提交的方式，这样即使上一次的异步提交失败，通过同步提交还能够进行补救，同步会一直重试，直到提交成功。通过finally在最后不管是否异常都会触发consumer.commit()来同步补救一次，确保偏移量不会丢失。 低级消费者(或简单消费者) 高级消费者 问题一: Kafka 高级消费者怎样才能达到最大吞吐量? 答:分区数量与线程数量一致。 问题二: 消费者消费能力不足时，如果提高并发? 答:1. 增加分区个数; 2. 增加消费者线程数; 3.自动提交 offset 在高阶消费者中，Offset 采用自动提交的方式。 自动提交时，假设 1s 提交一次 offset 的更新，设当前 offset=10，当消费者消费了 0.5s 的数据，offset 移动了 15，由于提交间隔为 1s，因此这一 offset 的更新并不会被提交，这时候我们写的消费者挂掉，重启后，消费者会去 ZooKeeper 上获取读取位置，获取到的 offset 仍为 10，它就会重复消费，这就是一个典型的重复消费问题。 高阶消费者存在一个弊端，即消费者消费到哪里由高阶消费者 API 进行提交，提交到 ZooKeeper，消费者线程不参与 offset 更新的过程，这就会造成数据丢失(消费者读取完成，高级消费者 API 的 offset 已经提交，但是还没有处理完成 Spark Streaming 挂掉，此时 offset 已经更新，无法再消费之前丢失的数据)，还有可能造成数据重复读取(消费者读取完成， 高级消费者 API 的 offset 还没有提交，读取数据已经处理完成后 Spark Streaming 挂掉，此时 offset 还没有更新，重启后会再次消费之前处理完成的数据)。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-12-10 00:02:28 "},"content/consumer_offset.html":{"url":"content/consumer_offset.html","title":"__consumer_offsets","keywords":"","body":"__consumer_offsets 查看__consumer_offsetstopic内容 启动kafka，并创建topic，生产者，消费者 // zk bin/zkServer.sh start conf/zoo_local.cfg // kafka broker bin/kafka-server-start.sh config/server.properties // 创建3分区的topic bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic test --replication-factor 1 --partitions 3 // 控制台生产者 bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test // 控制台消费者 bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning --new-consumer // 获取consumer group的group id(后面需要根据该id查询它的位移信息) bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list --new-consumer // 会返回一个消费组id，标记这个消费组，eg：console-consumer-82845 通过kafka-tool工具查看的一些情况 消费组 __consumer_offsets topic(可以看到这个topic有50个partition) 通过groupid得到消费组的便宜信息落到__consumer_offsets的哪个topic Math.abs(\"console-consumer-82845\".hashCode()) % 50 = 8， 则可以查看__consumer_offsets的8分区 通过如下命令查看，log内容形式:[Group, Topic, Partition]::[OffsetMetadata[Offset, Metadata], CommitTime, ExpirationTime] bin/kafka-simple-consumer-shell.sh --topic __consumer_offsets --partition 8 --broker-list localhost:9092 --formatter \"kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter\" 确认消费偏移量 testtopic各partition的情况 而根据log,确实是：partition 0: 39022，partition 1: 1，partition 2: 1 [console-consumer-82845,test,1]::[OffsetMetadata[1,NO_METADATA],CommitTime 1605872704862,ExpirationTime 1605959104862] [console-consumer-82845,test,0]::[OffsetMetadata[39022,NO_METADATA],CommitTime 1605872704862,ExpirationTime 1605959104862] [console-consumer-82845,test,2]::[OffsetMetadata[1,NO_METADATA],CommitTime 1605872704862,ExpirationTime 1605959104862] __consumer_offsets的每条消息的内容： key=group.id,topic,partition value=offset,metadata,timestamp Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-12-10 10:44:56 "},"content/rebalance.html":{"url":"content/rebalance.html","title":"再平衡","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 再平衡 什么情况下会发生再平衡? 再均衡协议 再均衡过程 消费者组状态以及状态转换 再平衡例子和策略？ Range（默认） Round Robin Sticky GroupCoordinator 基于zk的rebalance Coordinator 消费者与broker建立通信：FIND_COORDINATOR 加入GroupCoordinator：JOIN_GROUP 同步：SYNC_GROUP 心跳：HEARTBEAT 再平衡 什么情况下会发生再平衡? 有新的消费者加入消费组 有消费者宕机或下线 消费者并不一定需要真正下线，例如遇到长时间的GC、网络延迟导致消费者长时间未向 GroupCoordinator 发送心跳等情况时，GroupCoordinator 会认为消费者已经下线 有消费者主动退出消费组（发送 LeaveGroupRequest 请求）。比如客户端调用了 unsubscrible() 方法取消对某些主题的订阅 消费组所对应的 GroupCoordinator 节点发生了变更，例如coordinator挂了，集群选举出新的coordinator。GroupCoordinator 是 Kafka 服务端中用于管理消费组的组件。而消费者客户端中的 ConsumerCoordinator 组件负责与 GroupCoordinator 进行交互 消费组内所订阅的任一主题或者主题的partition数量发生变化 再均衡协议 Heartbeat请求：consumer需要定期给coordinator发送心跳来表明自己还活着 LeaveGroup请求：主动告诉coordinator我要离开consumer group SyncGroup请求：group leader把分配方案告诉组内所有成员 JoinGroup请求：成员请求加入组 DescribeGroup请求：显示组的所有信息，包括成员信息，协议名称，分配方案，订阅信息等。通常该请求是给管理员使用 再均衡过程 Kafka中分区再均衡主要分为两步，第一步是JoinGroup，第二步是SyncGroup Join， 顾名思义就是加入组。这一步中，所有成员都向coordinator发送JoinGroup请求，请求入组。一旦所有成员都发送了JoinGroup请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader：注意leader和coordinator不是一个概念。leader负责消费分配方案的制定。 Sync，这一步leader开始分配消费方案，即哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案封装进SyncGroup请求中发给coordinator，非leader也会发SyncGroup请求，只是内容为空。coordinator接收到分配方案之后会把方案塞进SyncGroup的response中发给各个consumer。这样组内的所有成员就都知道自己应该消费哪些分区了。 消费者组状态以及状态转换 Dead：组内已经没有任何成员的最终状态，组的元数据也已经被coordinator移除了。这种状态响应各种请求都是一个response： UNKNOWN_MEMBER_ID Empty：组内无成员，但是位移信息还没有过期。这种状态只能响应JoinGroup请求 PreparingRebalance：组准备开启新的rebalance，等待成员加入 AwaitingSync：正在等待leader consumer将分配方案传给各个成员 Stable：rebalance完成，可以开始消费了 再平衡例子和策略？ Range（默认） range策略：首先会计算每个consumer可以消费的分区个数，然后按照顺序将指定个数范围的分区分配给各个consumer；这种方式分配只是针对消费者订阅的topic的单个topic所有分区再分配 eg1: 10分区；2个机器实例，一个1个线程，一个2个线程（消费者线程排完序将会是C1-0, C2-0, C2-1） C1-0 将消费 0, 1, 2, 3 分区 C2-0 将消费 4, 5, 6 分区 C2-1 将消费 7, 8, 9 分区 eg2: 11分区 同上，可能是如下 C1-0 将消费 0, 1, 2, 3 分区 C2-0 将消费 4, 5, 6, 7 分区 C2-1 将消费 8, 9, 10 分区 eg3: 假如有2个主题(T1和T2)，分别有10个分区，那么最后分区分配的结果看起来如下 C1-0 将消费 T1主题的 0, 1, 2, 3 分区以及 T2主题的 0, 1, 2, 3分区 C2-0 将消费 T1主题的 4, 5, 6 分区以及 T2主题的 4, 5, 6分区 C2-1 将消费 T1主题的 7, 8, 9 分区以及 T2主题的 7, 8, 9分区 可以看出，C1-0 消费者线程比其他消费者线程多消费了2个分区，这就是Range strategy的一个很明显的弊端。 Round Robin 会采用轮询的方式将当前所有的分区依次分配给所有的consumer；这种分配策略是针对消费者消费的所有topic的所有分区进行分配。当有新的消费者加入或者有消费者退出，就会触发rebalance 使用RoundRobin策略有两个前提条件必须满足 同一个Consumer Group里面的所有消费者的num.streams必须相等； 每个消费者订阅的主题必须相同。 假如按照 hashCode 排序完的topic-partitions组依次为T1-5, T1-3, T1-0, T1-8, T1-2, T1-1, T1-4, T1-7, T1-6, T1-9，消费者线程排序为C1-0, C1-1, C2-0, C2-1，最后分区分配的结果为： C1-0 将消费 T1-5, T1-2, T1-6 分区； C1-1 将消费 T1-3, T1-1, T1-9 分区； C2-0 将消费 T1-0, T1-4 分区； C2-1 将消费 T1-8, T1-7 分区； Sticky sticky 英[ˈstɪki] 美[ˈstɪki] adj. 黏(性)的; 一面带黏胶的; 闷热的; n. 告事贴; Sticky策略是新版本中新增的策略，顾名思义，这种策略会保证再分配时已经分配过的分区尽量保证其能够继续由当前正在消费的consumer继续消费，当然，前提是每个consumer所分配的分区数量都大致相同，这样能够保证每个consumer消费压力比较均衡 eg:三个consumer：C0、C1和C2，三个topic：t0、t1和t2，这三个topic分别有1、2和3个分区；C0订阅了t0，C1订阅了t0和t1，C2则订阅了t0、t1和t2 分区排序结果 定于的consumer数量 订阅的consumer t2-0 1 c2 t2-1 1 c2 t2-2 1 c2 t1-0 2 c1, c2 t1-1 2 c1, c2 t0-0 3 c0，c2, c2 consumer进行排序:c0,c1,c2；然后将各个分区依次遍历分配给各个consumer，首先需要注意的是，这里的遍历并不是C0分配完了再分配给C1，而是每次分配分区的时候都整个的对所有的consumer从头开始遍历分配，如果当前consumer没有订阅当前分区，则会遍历下一个consumer。 最终分配结果如下 consumer topic-partition c0 t0-0 c1 t1-0, t1-1 c2 t2-0, t2-1, t2-2 eg2: 假设开始分配如下，然后c1宕机 consumer topic-partition c0 t0-0, t1-1, t3-0 c1 t1-1, t2-0, t3-1 c2 t1-0, t2-1 然后在平衡后 consumer topic-partition c0 t0-0, t1-1, t3-0, t2-0 c2 t1-0, t2-1, t0-1, t3-1 GroupCoordinator Kafka 的 Server 端主要有三块内容：GroupCoordinator、Controller 和 ReplicaManager，其中，GroupCoordinator 的内容是与 Consumer 端紧密结合在一起的，简单来说就是，GroupCoordinator 是负责进行 consumer 的 group 成员的rebalance与 offset 管理。GroupCoordinator 处理的 client 端请求类型可以看出来，它处理的请求类型主要有以下几种： ApiKeys.OFFSET_COMMIT; ApiKeys.OFFSET_FETCH; ApiKeys.JOIN_GROUP; ApiKeys.LEAVE_GROUP; ApiKeys.SYNC_GROUP; ApiKeys.DESCRIBE_GROUPS; ApiKeys.LIST_GROUPS; ApiKeys.HEARTBEAT; 而 Kafka Server 端要处理的请求总共有21 种，其中有 8 种是由 GroupCoordinator 来完成的。 基于zk的rebalance 在kafka0.9版本之前,consumer的rebalance是通过在zookeeper上注册watch完成的。每个consumer创建的时候，会在在Zookeeper上的路径为/consumers/[consumer group]/ids/[consumer id]下将自己的id注册到消费组下；然后在/consumers/[consumer group]/ids 和/brokers/ids下注册watch；最后强制自己在消费组启动rebalance。 这种做法很容易带来zk的羊群效应，任何Broker或者Consumer的增减都会触发所有的Consumer的Rebalance，造成集群内大量的调整；同时由于每个consumer单独通过zookeeper判断Broker和consumer宕机，由于zk的脑裂特性，同一时刻不同consumer通过zk看到的表现可能是不一样，这就可能会造成很多不正确的rebalance尝试；除此之外，由于consumer彼此独立，每个consumer都不知道其他consumer是否rebalance成功，可能会导致consumer group消费不正确。 Coordinator 对于每一个Consumer Group，Kafka集群为其从broker集群中选择一个broker作为其coordinator。coordinator主要做两件事： 维持group的成员组成。这包括加入新的成员，检测成员的存活性，清除不再存活的成员。 协调group成员的行为 Coordinator有如下几种类型： GroupCoordinator：broker端的，每个kafka server都有一个实例，管理部分的consumer group和它们的offset WorkerCoordinator：broker端的，管理GroupCoordinator程序，主要管理workers的分配。 ConsumerCoordinator：consumer端的，和GroupCoordinator通信的媒介。 ConsumerCoordinator是KafkaConsumer的一个成员，只负责与GroupCoordinator通信，所以真正的协调者还是GroupCoordinator。 对于 ConsumerGroup 而言，是根据其 group.id 进行 hash 并计算得到其具对应的 partition 值，该 partition leader 所在 Broker 即为该 Group 所对应的 GroupCoordinator，GroupCoordinator 会存储与该 group 相关的所有的 Meta 信息 每个分区有Leo, HW, Current Position, Last Committed Offset这些信息 消费者与broker建立通信：FIND_COORDINATOR 消费者需要确定它所属的消费组对应的 GroupCoordinator 所在的 broker，并创建与该 broker 相互通信的网络连接。如果消费者已经保存了与消费组对应的 GroupCoordinator 节点的信息，并且与它之间的网络连接是正常的，那么就可以进入第二阶段。否则，就需要向集群中的某个节点发送 FindCoordinatorRequest 请求来查找对应的 GroupCoordinator，这里的“某个节点”并非是集群中的任意节点，而是负载最小的节点。 加入GroupCoordinator：JOIN_GROUP 在成功找到消费组所对应的 GroupCoordinator 之后就进入加入消费组的阶段，在此阶段的消费者会向 GroupCoordinator 发送 JoinGroupRequest 请求，并处理响应。 选举消费组的leader 如果消费组内还没有 leader，那么第一个加入消费组的消费者即为消费组的 leader。如果某一时刻 leader 消费者由于某些原因退出了消费组，那么会重新选举一个新的 leader 选举分区分配策略 收集各个消费者支持的所有分配策略，组成候选集 candidates 每个消费者从候选集 candidates 中找出第一个自身支持的策略，为这个策略投上一票 计算候选集中各个策略的选票数，选票数最多的策略即为当前消费组的分配策略 同步：SYNC_GROUP leader 消费者根据在第二阶段中选举出来的分区分配策略来实施具体的分区分配，在此之后需要将分配的方案同步给各个消费者，通过 GroupCoordinator 这个“中间人”来负责转发同步分配方案的。 心跳：HEARTBEAT 进入这个阶段之后，消费组中的所有消费者就会处于正常工作状态。在正式消费之前，消费者还需要确定拉取消息的起始位置。假设之前已经将最后的消费位移提交到了 GroupCoordinator，并且 GroupCoordinator 将其保存到了 Kafka 内部的 __consumer_offsets 主题中，此时消费者可以通过 OffsetFetchRequest 请求获取上次提交的消费位移并从此处继续消费。 消费者通过向 GroupCoordinator 发送心跳来维持它们与消费组的从属关系，以及它们对分区的所有权关系。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区中的消息。心跳线程是一个独立的线程，可以在轮询消息的空档发送心跳。如果消费者停止发送心跳的时间足够长，则整个会话就被判定为过期，GroupCoordinator 也会认为这个消费者已经死亡，就会触发一次再均衡行为。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-12-09 18:28:38 "},"content/pro.html":{"url":"content/pro.html","title":"kafka常见面试题","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Kafka面试题 kafka为什么很快？ 顺序写入日志 零拷贝 mmap 预读数据/批处理(读一块然后处理) 日志分段(有类似跳表索引) 数据压缩 kafka使用page cache 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1？ Kafka中是怎么体现消息顺序性的？如何保证数据的一致性? 如何保证数据不会丢失或者重复消费的情况？做过哪些预防措施，增么解决以上问题的 Topic 分区副本, 可靠性保证？ kafka重复消费的根本原因就是\"数据消费了，但是offset没更新\"！而我们要探究一般什么情况下会导致offset没更新？ 为了避免磁盘被占满，kafka会周期性的删除陈旧的消息，删除策略是什么? kafka集群多Topic性能下降 死信队列（Dead-Letter Queue） 消息中间件对比（旧） 2.数据传输的事物定义有哪三种？ Kafka面试题 kafka为什么很快？ 顺序写入日志 追加数据到日志文件尾部，顺序IO 零拷贝 mmap 即便是顺序写入硬盘，硬盘的访问速度还是不可能追上内存。所以Kafka的数据并不是实时的写入硬盘，它充分利用了现代操作系统 分页存储 来利用内存提高I/O效率。 Memory Mapped Files(后面简称mmap)也被翻译成 内存映射文件 ，在64位操作系统中一般可以表示20G的数据文件，它的工作原理是直接利用操作系统的Page来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上（操作系统在适当的时候）。 通过mmap，进程像读写硬盘一样读写内存（当然是虚拟机内存），也不必关心内存的大小有虚拟内存为我们兜底。 使用这种方式可以获取很大的I/O提升， 省去了用户空间到内核空间 复制的开销（调用文件的read会把数据先放到内核空间的内存中，然后再复制到用户空间的内存中。）也有一个很明显的缺陷——不可靠， 写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘。 Kafka提供了一个参数——producer.type来控制是不是主动flush，如果Kafka写入到mmap之后就立即flush然后再返回Producer叫 同步 (sync)；写入mmap之后立即返回Producer不调用flush叫 异步 (async)。 在内核版本2.1中，引入了sendfile系统调用，以简化网络上和两个本地文件之间的数据传输。 sendfile的引入不仅减少了数据复制，还减少了上下文切换。 sendfile(socket, file, len);,运行流程如下： sendfile系统调用，文件数据被copy至内核缓冲区 再从内核缓冲区copy至内核中socket相关的缓冲区 最后再socket相关的缓冲区copy到协议引擎 相较传统read/write方式，2.1版本内核引进的sendfile已经减少了内核缓冲区到user缓冲区，再由user缓冲区到socket相关缓冲区的文件copy，而在内核版本2.4之后，文件描述符结果被改变，sendfile实现了更简单的方式，再次减少了一次copy操作。 在apache，nginx，lighttpd等web服务器当中，都有一项sendfile相关的配置，使用sendfile可以大幅提升文件传输性能。 Kafka把所有的消息都存放在一个一个的文件中，当消费者需要数据的时候Kafka直接把文件发送给消费者，配合mmap作为文件读写方式，直接把它传给sendfile。 预读数据/批处理(读一块然后处理) 日志分段(有类似跳表索引) 数据压缩 当启用压缩时，对批处理的影响特别明显，因为随着数据大小的增加，压缩通常会变得更有效 特别是在使用基于文本的格式时，比如 JSON，压缩的效果会非常明显，压缩比通常在5x到7x之间 此外，记录的批处理主要作为一个客户端操作，负载在传递的过程中，不仅对网络带宽有积极影响，而且对服务端的磁盘 I/O 利用率也有积极影响 kafka使用page cache ~ free -m total used free shared buffers cached Mem: 128956 96440 32515 0 5368 39900 -/+ buffers/cache: 51172 77784 Swap: 16002 0 16001 page cache用于缓存文件的页数据，buffer cache用于缓存块设备（如磁盘）的块数据。页是逻辑上的概念，因此page cache是与文件系统同级的；块是物理上的概念，因此buffer cache是与块设备驱动程序同级的。 producer生产消息时，会使用pwrite()系统调用【对应到Java NIO中是FileChannel.write() API】按偏移量写入数据，并且都会先写入page cache里。consumer消费消息时，会使用sendfile()系统调用【对应FileChannel.transferTo() API】，零拷贝地将数据从page cache传输到broker的Socket buffer，再通过网络传输。 同时，page cache中的数据会随着内核中flusher线程的调度以及对sync()/fsync()的调用写回到磁盘，就算进程崩溃，也不用担心数据丢失。另外，如果consumer要消费的消息不在page cache里，才会去磁盘读取，并且会顺便预读出一些相邻的块放入page cache，以方便下一次读取。 如果Kafka producer的生产速率与consumer的消费速率相差不大，那么就能几乎只靠对broker page cache的读写完成整个生产-消费过程，磁盘访问非常少。这个结论俗称为\"读写空中接力\"。并且Kafka持久化消息到各个topic的partition文件时，是只追加的顺序写，充分利用了磁盘顺序访问快的特性，效率高 美团：Kafka文件存储机制那些事 作者：LittleMagic 链接：https://www.jianshu.com/p/92f33aa0ff52 来源：简书 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1？ offset+1 Kafka中是怎么体现消息顺序性的？如何保证数据的一致性? 每个分区内，每条消息都有一个offset，故只能保证分区内有序 HW，LEO维护 副本为3，副本0位leader，副本1和2位follower，在ISR列表里面副本0已经写入了message4，但是consumer只能读取message2，这是因为所有副本都同步了message2，只有High water mark以上的message才能被consumer读取，而High water mark取决于ISR列表里偏移量最小的分区，对应上图中的副本2 所以在message还没有被follower同步完成时会被认为是\"不安全的\"，如果consumer读取了副本0中的message4，这时候leader挂了，选举了副本1为新的leader，别的消费者去消费的时候就没有message4，就会造成不同的consumer消费的数据不一致，破坏了数据的一致性。 在引入了High water mark机制后，会导致broker之间的消息复制因为某些原因变慢，消息到达消费者的时间也会延长(需要等消息复制完了才能消费)，延迟的时间可以通过参数来设置：replica.lag.time.max.ms(它指定了副本在复制消息时可被允许的最大延迟时间) 如何保证数据不会丢失或者重复消费的情况？做过哪些预防措施，增么解决以上问题的 发送： 同步发送数据 ACK = -1（all） 消费：（再平衡） 自己维护offset，避免重复消费（低级API） Topic 分区副本, 可靠性保证？ 保证单个副本中的顺序性 Kafka 的分区多副本架构是 Kafka 可靠性保证的核心，把消息写入多个副本可以使 Kafka 在发生崩溃时仍能保证消息的持久性。 同步复制： 只有所有的follower把数据拿过去后才commit，一致性好，可用性不高。 异步复制： 只要leader拿到数据立即commit，等follower慢慢去复制，可用性高，立即返回，一致性差一些。 Commit：是指leader告诉客户端，这条数据写成功了。kafka尽量保证commit后立即leader挂掉，其他flower都有该条数据。 kafka不是完全同步，也不是完全异步，是一种ISR机制： leader会维护一个与其基本保持同步的Replica列表，该列表称为ISR(in-sync Replica)，每个Partition都会有一个ISR，而且是由leader动态维护 如果一个flower比一个leader落后太多，或者超过一定时间未发起数据复制请求，则leader将其重ISR中移除 当ISR中所有Replica都向Leader发送ACK时，leader才commit kafka重复消费的根本原因就是\"数据消费了，但是offset没更新\"！而我们要探究一般什么情况下会导致offset没更新？ 原因1：强行kill线程，导致消费后的数据，offset没有提交（消费系统宕机、重启等) 原因2：设置offset为自动提交，关闭kafka时，如果在close之前，调用 consumer.unsubscribe() 则有可能部分offset没提交，下次重启会重复消费 原因3:（重复消费最常见的原因）：消费后的数据，当offset还没有提交时，partition就断开连接。比如，通常会遇到消费的数据，处理很耗时，导致超过了Kafka的session timeout时间（0.10.x版本默认是30秒），那么就会re-blance重平衡，此时有一定几率offset没提交，会导致重平衡后重复消费 原因4：当消费者重新分配partition的时候，可能出现从头开始消费的情况，导致重发问题。 原因5：当消费者消费的速度很慢的时候，可能在一个session周期内还未完成，导致心跳机制检测报告出问题。 原因6：并发很大，可能在规定的时间（session.time.out默认30s）内没有消费完，就会可能导致rebalance重平衡，导致一部分offset自动提交失败，然后重平衡后重复消费 为了避免磁盘被占满，kafka会周期性的删除陈旧的消息，删除策略是什么? 一种是根据消息保留的时间 一种是根据topic存储的数据大小 kafka集群多Topic性能下降 参考：Kafka vs RocketMQ——多Topic对性能稳定性的影响-转自阿里中间件 死信队列（Dead-Letter Queue） 当一条消息初次消费失败，消息队列 MQ 会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列 MQ 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中，这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），存储死信消息的特殊队列称为死信队列（Dead-Letter Queue） 与此对应的还有一个“回退队列”的概念，试想如果消费者在消费时发生了异常，那么就不会对这一次消费进行确认（Ack）,进而发生回滚消息的操作之后消息始终会放在队列的顶部，然后不断被处理和回滚，导致队列陷入死循环。为了解决这个问题，可以为每个队列设置一个回退队列，它和死信队列都是为异常的处理提供的一种机制保障。实际情况下，回退队列的角色可以由死信队列和重试队列来扮演 重试队列其实可以看成是一种回退队列，具体指消费端消费消息失败时，为防止消息无故丢失而重新将消息回滚到Broker中。与回退队列不同的是重试队列一般分成多个重试等级，每个重试等级一般也会设置重新投递延时，重试次数越多投递延时就越大 eg: 消息第一次消费失败入重试队列Q1，Q1的重新投递延迟为5s，在5s过后重新投递该消息；如果消息再次消费失败则入重试队列Q2，Q2的重新投递延迟为10s，在10s过后再次投递该消息。以此类推，重试越多次重新投递的时间就越久，为此需要设置一个上限，超过投递次数就入死信队列。重试队列与延迟队列有相同的地方，都是需要设置延迟级别，它们彼此的区别是：延迟队列动作由内部触发，重试队列动作由外部消费端触发；延迟队列作用一次，而重试队列的作用范围会向后传递 注意：Kafka不支持重试机制也就不支持消息重试，也不支持死信队列，因此使用kafka做消息队列时，如果遇到了消息在业务处理时出现异常的场景时，需要额外实现消息重试的功能。 消息中间件对比（旧） 2.数据传输的事物定义有哪三种？ 数据传输的事务定义通常有以下三种级别： 至多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输 最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输. 精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被一次而且仅仅被传输一次，这是大家所期望的 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-12-10 10:13:57 "}}